{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>309.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.54</td>\n",
       "      <td>2936.77</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>215.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.00</td>\n",
       "      <td>13.47</td>\n",
       "      <td>3447.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>346.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.33</td>\n",
       "      <td>19.97</td>\n",
       "      <td>5999.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc   v(g)   ev(g)   iv(g)    n        v    l       d      i        e  \\\n",
       "0   1.1    1.4     1.4     1.4   1.3    1.30  1.30   1.30   1.30     1.30   \n",
       "1   1.0    1.0     1.0     1.0   1.0    1.00  1.00   1.00   1.00     1.00   \n",
       "2  24.0    5.0     1.0     3.0  63.0  309.13  0.11   9.50  32.54  2936.77   \n",
       "3  20.0    4.0     4.0     2.0  47.0  215.49  0.06  16.00  13.47  3447.89   \n",
       "4  24.0    6.0     6.0     2.0  72.0  346.13  0.06  17.33  19.97  5999.58   \n",
       "\n",
       "   ...   lOCode   lOComment   lOBlank   locCodeAndComment   uniq_Op  \\\n",
       "0  ...        2           2         2                   2       1.2   \n",
       "1  ...        1           1         1                   1       1.0   \n",
       "2  ...        1           0         6                   0      15.0   \n",
       "3  ...        0           0         3                   0      16.0   \n",
       "4  ...        0           0         3                   0      16.0   \n",
       "\n",
       "    uniq_Opnd   total_Op   total_Opnd   branchCount   defects  \n",
       "0         1.2        1.2          1.2           1.4     False  \n",
       "1         1.0        1.0          1.0           1.0      True  \n",
       "2        15.0       44.0         19.0           9.0     False  \n",
       "3         8.0       31.0         16.0           7.0     False  \n",
       "4        12.0       46.0         26.0          11.0     False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"dataset/CM1.csv\")\n",
    "data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>t</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>4.980000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.644779</td>\n",
       "      <td>5.382329</td>\n",
       "      <td>2.490763</td>\n",
       "      <td>3.528916</td>\n",
       "      <td>143.956426</td>\n",
       "      <td>900.175823</td>\n",
       "      <td>0.146325</td>\n",
       "      <td>15.829378</td>\n",
       "      <td>38.455361</td>\n",
       "      <td>3.488493e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1938.056124</td>\n",
       "      <td>3.787149</td>\n",
       "      <td>12.283133</td>\n",
       "      <td>11.534137</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>15.199197</td>\n",
       "      <td>25.452209</td>\n",
       "      <td>88.389960</td>\n",
       "      <td>55.570683</td>\n",
       "      <td>9.348193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.753572</td>\n",
       "      <td>8.347359</td>\n",
       "      <td>3.658847</td>\n",
       "      <td>5.464398</td>\n",
       "      <td>221.049888</td>\n",
       "      <td>1690.814334</td>\n",
       "      <td>0.159337</td>\n",
       "      <td>15.330960</td>\n",
       "      <td>36.996297</td>\n",
       "      <td>1.341647e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>7453.591519</td>\n",
       "      <td>8.508658</td>\n",
       "      <td>25.828605</td>\n",
       "      <td>19.981476</td>\n",
       "      <td>0.100120</td>\n",
       "      <td>9.617815</td>\n",
       "      <td>33.925816</td>\n",
       "      <td>134.917513</td>\n",
       "      <td>86.969527</td>\n",
       "      <td>15.072219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>102.190000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>5.630000</td>\n",
       "      <td>16.210000</td>\n",
       "      <td>6.061700e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>33.672500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>329.820000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>11.640000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>3.677620e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>204.310000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>151.750000</td>\n",
       "      <td>861.460000</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>21.142500</td>\n",
       "      <td>46.900000</td>\n",
       "      <td>1.663334e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>924.075000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>94.750000</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>423.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>2075.000000</td>\n",
       "      <td>17124.280000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>125.770000</td>\n",
       "      <td>293.680000</td>\n",
       "      <td>2.153691e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>119649.480000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>1261.000000</td>\n",
       "      <td>814.000000</td>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              loc        v(g)       ev(g)       iv(g)           n   \\\n",
       "count  498.000000  498.000000  498.000000  498.000000   498.000000   \n",
       "mean    29.644779    5.382329    2.490763    3.528916   143.956426   \n",
       "std     42.753572    8.347359    3.658847    5.464398   221.049888   \n",
       "min      1.000000    1.000000    1.000000    1.000000     1.000000   \n",
       "25%      8.000000    1.000000    1.000000    1.000000    25.000000   \n",
       "50%     17.000000    3.000000    1.000000    2.000000    67.500000   \n",
       "75%     31.000000    6.000000    1.000000    4.000000   151.750000   \n",
       "max    423.000000   96.000000   30.000000   63.000000  2075.000000   \n",
       "\n",
       "                  v          l            d           i             e  ...  \\\n",
       "count    498.000000  498.000000  498.000000  498.000000  4.980000e+02  ...   \n",
       "mean     900.175823    0.146325   15.829378   38.455361  3.488493e+04  ...   \n",
       "std     1690.814334    0.159337   15.330960   36.996297  1.341647e+05  ...   \n",
       "min        0.000000    0.000000    0.000000    0.000000  0.000000e+00  ...   \n",
       "25%      102.190000    0.050000    5.630000   16.210000  6.061700e+02  ...   \n",
       "50%      329.820000    0.090000   11.640000   27.400000  3.677620e+03  ...   \n",
       "75%      861.460000    0.177500   21.142500   46.900000  1.663334e+04  ...   \n",
       "max    17124.280000    1.300000  125.770000  293.680000  2.153691e+06  ...   \n",
       "\n",
       "                   t      lOCode   lOComment     lOBlank   locCodeAndComment  \\\n",
       "count     498.000000  498.000000  498.000000  498.000000          498.000000   \n",
       "mean     1938.056124    3.787149   12.283133   11.534137            0.006024   \n",
       "std      7453.591519    8.508658   25.828605   19.981476            0.100120   \n",
       "min         0.000000    0.000000    0.000000    0.000000            0.000000   \n",
       "25%        33.672500    0.000000    0.000000    1.000000            0.000000   \n",
       "50%       204.310000    1.000000    4.000000    5.000000            0.000000   \n",
       "75%       924.075000    4.000000   14.000000   13.000000            0.000000   \n",
       "max    119649.480000   80.000000  339.000000  164.000000            2.000000   \n",
       "\n",
       "          uniq_Op   uniq_Opnd     total_Op   total_Opnd   branchCount  \n",
       "count  498.000000  498.000000   498.000000   498.000000    498.000000  \n",
       "mean    15.199197   25.452209    88.389960    55.570683      9.348193  \n",
       "std      9.617815   33.925816   134.917513    86.969527     15.072219  \n",
       "min      1.000000    0.000000     1.000000     0.000000      1.000000  \n",
       "25%      9.000000    7.000000    15.000000    10.000000      1.000000  \n",
       "50%     14.000000   15.000000    42.000000    26.000000      5.000000  \n",
       "75%     20.000000   30.000000    94.750000    59.750000     11.000000  \n",
       "max     72.000000  314.000000  1261.000000   814.000000    162.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1, 1,\n",
       "       1, 1, 1.0, 1.0, 1.0, 1.0, 1.0, 1], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(498):\n",
    "    if data2[i][21]==True:\n",
    "        data2[i][21]=1\n",
    "    else:\n",
    "        data2[i][21]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.1,   1.4,   1.4, ...,   1.2,   1.2,   1.4],\n",
       "       [  1. ,   1. ,   1. , ...,   1. ,   1. ,   1. ],\n",
       "       [ 24. ,   5. ,   1. , ...,  44. ,  19. ,   9. ],\n",
       "       ...,\n",
       "       [ 82. ,  11. ,   3. , ..., 285. , 190. ,  21. ],\n",
       "       [ 10. ,   2. ,   1. , ...,  19. ,  13. ,   3. ],\n",
       "       [ 28. ,   6. ,   5. , ...,  67. ,  37. ,  11. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((898, 21), (898,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(898, 21, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "X_res=X_res.reshape(898,21,1)\n",
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "threshold = 0.5  \n",
    "\n",
    "def mcc_metric(y_true, y_pred):\n",
    "    predicted = tf.cast(tf.greater(y_pred, threshold), tf.float32)\n",
    "    true_pos = tf.math.count_nonzero(predicted * y_true)\n",
    "    true_neg = tf.math.count_nonzero((predicted - 1) * (y_true - 1))\n",
    "    false_pos = tf.math.count_nonzero(predicted * (y_true - 1))\n",
    "    false_neg = tf.math.count_nonzero((predicted - 1) * y_true)\n",
    "    x = tf.cast((true_pos + false_pos) * (true_pos + false_neg) \n",
    "        * (true_neg + false_pos) * (true_neg + false_neg), tf.float32)\n",
    "    return tf.cast((true_pos * true_neg) - (false_pos * false_neg), tf.float32) / tf.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "from keras import regularizers\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=12, kernel_size=4 , input_shape=(21,1),activation= 'relu', kernel_regularizer=regularizers.l2(0.001) ))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(21, activation= 'relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dense(num_classes, activation= 'sigmoid', kernel_regularizer=regularizers.l2(0.001) ))\n",
    "# Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy' ,f1_m,recall_m,mcc_metric])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 718 samples, validate on 180 samples\n",
      "Epoch 1/50\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 1147.7010 - accuracy: 0.4986 - f1_m: 0.3591 - recall_m: 0.3564 - mcc_metric: nan - val_loss: 543.4469 - val_accuracy: 0.4611 - val_f1_m: 0.3482 - val_recall_m: 0.2967 - val_mcc_metric: -0.1009\n",
      "Epoch 2/50\n",
      "718/718 [==============================] - 0s 143us/step - loss: 499.0716 - accuracy: 0.5153 - f1_m: 0.4467 - recall_m: 0.4161 - mcc_metric: 0.0505 - val_loss: 196.3487 - val_accuracy: 0.5667 - val_f1_m: 0.5761 - val_recall_m: 0.6050 - val_mcc_metric: 0.1069\n",
      "Epoch 3/50\n",
      "718/718 [==============================] - 0s 153us/step - loss: 190.7086 - accuracy: 0.5320 - f1_m: 0.5930 - recall_m: 0.7333 - mcc_metric: nan - val_loss: 92.8406 - val_accuracy: 0.5528 - val_f1_m: 0.6756 - val_recall_m: 0.9367 - val_mcc_metric: 0.1669\n",
      "Epoch 4/50\n",
      "718/718 [==============================] - 0s 147us/step - loss: 123.4935 - accuracy: 0.5877 - f1_m: 0.6113 - recall_m: 0.6793 - mcc_metric: 0.2026 - val_loss: 33.4213 - val_accuracy: 0.5611 - val_f1_m: 0.6814 - val_recall_m: 0.9450 - val_mcc_metric: 0.1861\n",
      "Epoch 5/50\n",
      "718/718 [==============================] - 0s 123us/step - loss: 57.4649 - accuracy: 0.5362 - f1_m: 0.6523 - recall_m: 0.8843 - mcc_metric: 0.1241 - val_loss: 47.6467 - val_accuracy: 0.5806 - val_f1_m: 0.6888 - val_recall_m: 0.9367 - val_mcc_metric: 0.2283\n",
      "Epoch 6/50\n",
      "718/718 [==============================] - 0s 149us/step - loss: 60.2625 - accuracy: 0.5299 - f1_m: 0.6391 - recall_m: 0.8436 - mcc_metric: 0.0773 - val_loss: 28.8613 - val_accuracy: 0.5667 - val_f1_m: 0.6468 - val_recall_m: 0.7917 - val_mcc_metric: 0.1538\n",
      "Epoch 7/50\n",
      "718/718 [==============================] - 0s 216us/step - loss: 54.2069 - accuracy: 0.5662 - f1_m: 0.6534 - recall_m: 0.8307 - mcc_metric: 0.1707 - val_loss: 61.7055 - val_accuracy: 0.5917 - val_f1_m: 0.5542 - val_recall_m: 0.5167 - val_mcc_metric: 0.1804\n",
      "Epoch 8/50\n",
      "718/718 [==============================] - 0s 373us/step - loss: 39.2767 - accuracy: 0.5731 - f1_m: 0.6587 - recall_m: 0.8222 - mcc_metric: 0.1937 - val_loss: 50.8289 - val_accuracy: 0.5944 - val_f1_m: 0.5622 - val_recall_m: 0.5400 - val_mcc_metric: 0.1719\n",
      "Epoch 9/50\n",
      "718/718 [==============================] - 0s 216us/step - loss: 43.9856 - accuracy: 0.5836 - f1_m: 0.6468 - recall_m: 0.7865 - mcc_metric: 0.2173 - val_loss: 34.6685 - val_accuracy: 0.6000 - val_f1_m: 0.5157 - val_recall_m: 0.4300 - val_mcc_metric: 0.2142\n",
      "Epoch 10/50\n",
      "718/718 [==============================] - 0s 455us/step - loss: 37.0571 - accuracy: 0.5829 - f1_m: 0.5886 - recall_m: 0.6213 - mcc_metric: 0.1787 - val_loss: 72.1495 - val_accuracy: 0.5472 - val_f1_m: 0.6810 - val_recall_m: 0.9733 - val_mcc_metric: 0.1762\n",
      "Epoch 11/50\n",
      "718/718 [==============================] - 0s 206us/step - loss: 45.0552 - accuracy: 0.6177 - f1_m: 0.6436 - recall_m: 0.7393 - mcc_metric: 0.2706 - val_loss: 36.8013 - val_accuracy: 0.6111 - val_f1_m: 0.6948 - val_recall_m: 0.8750 - val_mcc_metric: 0.2760\n",
      "Epoch 12/50\n",
      "718/718 [==============================] - 0s 159us/step - loss: 49.4221 - accuracy: 0.6107 - f1_m: 0.6035 - recall_m: 0.6181 - mcc_metric: 0.2219 - val_loss: 37.4018 - val_accuracy: 0.6444 - val_f1_m: 0.6940 - val_recall_m: 0.8267 - val_mcc_metric: 0.2921\n",
      "Epoch 13/50\n",
      "718/718 [==============================] - 0s 154us/step - loss: 23.7474 - accuracy: 0.5829 - f1_m: 0.6215 - recall_m: 0.7216 - mcc_metric: 0.1952 - val_loss: 119.4537 - val_accuracy: 0.5111 - val_f1_m: 0.5233 - val_recall_m: 0.5233 - val_mcc_metric: 0.0467\n",
      "Epoch 14/50\n",
      "718/718 [==============================] - 0s 347us/step - loss: 136.3662 - accuracy: 0.5299 - f1_m: 0.5426 - recall_m: 0.5535 - mcc_metric: 0.0718 - val_loss: 37.7182 - val_accuracy: 0.6306 - val_f1_m: 0.6694 - val_recall_m: 0.7700 - val_mcc_metric: 0.2555\n",
      "Epoch 15/50\n",
      "718/718 [==============================] - 0s 198us/step - loss: 47.8239 - accuracy: 0.5648 - f1_m: 0.5370 - recall_m: 0.6127 - mcc_metric: 0.1746 - val_loss: 84.7227 - val_accuracy: 0.5389 - val_f1_m: 0.2408 - val_recall_m: 0.1500 - val_mcc_metric: 0.1255\n",
      "Epoch 16/50\n",
      "718/718 [==============================] - 0s 429us/step - loss: 42.8622 - accuracy: 0.5857 - f1_m: 0.5857 - recall_m: 0.6508 - mcc_metric: 0.2090 - val_loss: 75.4053 - val_accuracy: 0.5833 - val_f1_m: 0.4056 - val_recall_m: 0.2817 - val_mcc_metric: 0.2264\n",
      "Epoch 17/50\n",
      "718/718 [==============================] - 0s 177us/step - loss: 50.0600 - accuracy: 0.5494 - f1_m: 0.5490 - recall_m: 0.6047 - mcc_metric: 0.1248 - val_loss: 27.2828 - val_accuracy: 0.5750 - val_f1_m: 0.5632 - val_recall_m: 0.5617 - val_mcc_metric: 0.1251\n",
      "Epoch 18/50\n",
      "718/718 [==============================] - 0s 282us/step - loss: 31.0009 - accuracy: 0.6031 - f1_m: 0.6091 - recall_m: 0.6514 - mcc_metric: 0.2107 - val_loss: 23.6595 - val_accuracy: 0.6222 - val_f1_m: 0.6455 - val_recall_m: 0.7017 - val_mcc_metric: 0.2297\n",
      "Epoch 19/50\n",
      "718/718 [==============================] - 0s 235us/step - loss: 30.8383 - accuracy: 0.6079 - f1_m: 0.5860 - recall_m: 0.6293 - mcc_metric: 0.2519 - val_loss: 53.6662 - val_accuracy: 0.5417 - val_f1_m: 0.5820 - val_recall_m: 0.6217 - val_mcc_metric: 0.1061\n",
      "Epoch 20/50\n",
      "718/718 [==============================] - 0s 232us/step - loss: 31.4091 - accuracy: 0.5731 - f1_m: 0.5668 - recall_m: 0.5942 - mcc_metric: 0.1571 - val_loss: 28.7413 - val_accuracy: 0.6056 - val_f1_m: 0.5028 - val_recall_m: 0.4000 - val_mcc_metric: 0.2474\n",
      "Epoch 21/50\n",
      "718/718 [==============================] - 0s 181us/step - loss: 22.0998 - accuracy: 0.5947 - f1_m: 0.5391 - recall_m: 0.5191 - mcc_metric: 0.1827 - val_loss: 20.0830 - val_accuracy: 0.6361 - val_f1_m: 0.5990 - val_recall_m: 0.5367 - val_mcc_metric: 0.2920\n",
      "Epoch 22/50\n",
      "718/718 [==============================] - 0s 145us/step - loss: 24.0821 - accuracy: 0.6058 - f1_m: 0.5304 - recall_m: 0.5443 - mcc_metric: 0.2427 - val_loss: 39.6328 - val_accuracy: 0.5556 - val_f1_m: 0.6820 - val_recall_m: 0.9583 - val_mcc_metric: 0.1870\n",
      "Epoch 23/50\n",
      "718/718 [==============================] - 0s 273us/step - loss: 30.3427 - accuracy: 0.6212 - f1_m: 0.6063 - recall_m: 0.6311 - mcc_metric: 0.2445 - val_loss: 10.9397 - val_accuracy: 0.6444 - val_f1_m: 0.6209 - val_recall_m: 0.5883 - val_mcc_metric: 0.2821\n",
      "Epoch 24/50\n",
      "718/718 [==============================] - 0s 264us/step - loss: 25.0020 - accuracy: 0.6086 - f1_m: 0.5373 - recall_m: 0.5215 - mcc_metric: 0.2398 - val_loss: 13.1513 - val_accuracy: 0.6000 - val_f1_m: 0.6947 - val_recall_m: 0.9033 - val_mcc_metric: 0.2597\n",
      "Epoch 25/50\n",
      "718/718 [==============================] - 0s 272us/step - loss: 22.4512 - accuracy: 0.6198 - f1_m: 0.6276 - recall_m: 0.6624 - mcc_metric: 0.2439 - val_loss: 20.4470 - val_accuracy: 0.6417 - val_f1_m: 0.6444 - val_recall_m: 0.6667 - val_mcc_metric: 0.2657\n",
      "Epoch 26/50\n",
      "718/718 [==============================] - 0s 303us/step - loss: 13.3839 - accuracy: 0.6233 - f1_m: 0.6063 - recall_m: 0.6006 - mcc_metric: 0.2458 - val_loss: 14.2795 - val_accuracy: 0.6667 - val_f1_m: 0.5997 - val_recall_m: 0.5083 - val_mcc_metric: 0.3398\n",
      "Epoch 27/50\n",
      "718/718 [==============================] - 0s 261us/step - loss: 17.3147 - accuracy: 0.6100 - f1_m: 0.6087 - recall_m: 0.6276 - mcc_metric: 0.2422 - val_loss: 21.3427 - val_accuracy: 0.6750 - val_f1_m: 0.6872 - val_recall_m: 0.7250 - val_mcc_metric: 0.3403\n",
      "Epoch 28/50\n",
      "718/718 [==============================] - 0s 142us/step - loss: 36.3624 - accuracy: 0.6281 - f1_m: 0.6144 - recall_m: 0.6431 - mcc_metric: 0.2823 - val_loss: 16.9644 - val_accuracy: 0.6111 - val_f1_m: 0.6964 - val_recall_m: 0.8950 - val_mcc_metric: 0.2695\n",
      "Epoch 29/50\n",
      "718/718 [==============================] - 0s 319us/step - loss: 15.3702 - accuracy: 0.6233 - f1_m: 0.6264 - recall_m: 0.6544 - mcc_metric: 0.2600 - val_loss: 7.9776 - val_accuracy: 0.6889 - val_f1_m: 0.7369 - val_recall_m: 0.8750 - val_mcc_metric: 0.4079\n",
      "Epoch 30/50\n",
      "718/718 [==============================] - 0s 202us/step - loss: 16.1985 - accuracy: 0.6407 - f1_m: 0.6036 - recall_m: 0.5902 - mcc_metric: 0.3135 - val_loss: 22.7161 - val_accuracy: 0.6083 - val_f1_m: 0.4384 - val_recall_m: 0.3050 - val_mcc_metric: 0.2777\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718/718 [==============================] - 0s 156us/step - loss: 32.5722 - accuracy: 0.5961 - f1_m: 0.5867 - recall_m: 0.6098 - mcc_metric: 0.2182 - val_loss: 33.1567 - val_accuracy: 0.6333 - val_f1_m: 0.6067 - val_recall_m: 0.5733 - val_mcc_metric: 0.2559\n",
      "Epoch 32/50\n",
      "718/718 [==============================] - 0s 345us/step - loss: 32.6633 - accuracy: 0.5787 - f1_m: 0.5869 - recall_m: 0.5938 - mcc_metric: 0.1668 - val_loss: 24.9464 - val_accuracy: 0.5833 - val_f1_m: 0.5776 - val_recall_m: 0.5583 - val_mcc_metric: 0.1838\n",
      "Epoch 33/50\n",
      "718/718 [==============================] - 0s 275us/step - loss: 14.5226 - accuracy: 0.6560 - f1_m: 0.6393 - recall_m: 0.6396 - mcc_metric: 0.3228 - val_loss: 21.2007 - val_accuracy: 0.6139 - val_f1_m: 0.6965 - val_recall_m: 0.8883 - val_mcc_metric: 0.2783\n",
      "Epoch 34/50\n",
      "718/718 [==============================] - 0s 299us/step - loss: 16.8689 - accuracy: 0.6177 - f1_m: 0.6199 - recall_m: 0.6591 - mcc_metric: 0.2717 - val_loss: 17.4310 - val_accuracy: 0.6611 - val_f1_m: 0.6468 - val_recall_m: 0.6317 - val_mcc_metric: 0.3104\n",
      "Epoch 35/50\n",
      "718/718 [==============================] - 0s 328us/step - loss: 44.0707 - accuracy: 0.6052 - f1_m: 0.5929 - recall_m: 0.6084 - mcc_metric: 0.2205 - val_loss: 43.1722 - val_accuracy: 0.5639 - val_f1_m: 0.2457 - val_recall_m: 0.1417 - val_mcc_metric: 0.2491\n",
      "Epoch 36/50\n",
      "718/718 [==============================] - 0s 362us/step - loss: 26.8553 - accuracy: 0.6184 - f1_m: 0.5884 - recall_m: 0.5926 - mcc_metric: 0.2710 - val_loss: 10.0423 - val_accuracy: 0.6833 - val_f1_m: 0.7338 - val_recall_m: 0.8683 - val_mcc_metric: 0.4040\n",
      "Epoch 37/50\n",
      "718/718 [==============================] - 0s 396us/step - loss: 13.9066 - accuracy: 0.6253 - f1_m: 0.6042 - recall_m: 0.6139 - mcc_metric: 0.2832 - val_loss: 4.1794 - val_accuracy: 0.7333 - val_f1_m: 0.7488 - val_recall_m: 0.7933 - val_mcc_metric: 0.4743\n",
      "Epoch 38/50\n",
      "718/718 [==============================] - 0s 376us/step - loss: 9.8144 - accuracy: 0.6504 - f1_m: 0.6242 - recall_m: 0.6092 - mcc_metric: 0.3117 - val_loss: 16.1601 - val_accuracy: 0.6361 - val_f1_m: 0.7141 - val_recall_m: 0.8983 - val_mcc_metric: 0.3306\n",
      "Epoch 39/50\n",
      "718/718 [==============================] - 0s 304us/step - loss: 18.0985 - accuracy: 0.6421 - f1_m: 0.5744 - recall_m: 0.5893 - mcc_metric: 0.2901 - val_loss: 29.3753 - val_accuracy: 0.6389 - val_f1_m: 0.4628 - val_recall_m: 0.3183 - val_mcc_metric: 0.3487\n",
      "Epoch 40/50\n",
      "718/718 [==============================] - 0s 386us/step - loss: 33.8315 - accuracy: 0.6086 - f1_m: 0.5627 - recall_m: 0.5511 - mcc_metric: 0.2511 - val_loss: 20.7533 - val_accuracy: 0.6611 - val_f1_m: 0.6287 - val_recall_m: 0.5833 - val_mcc_metric: 0.3137\n",
      "Epoch 41/50\n",
      "718/718 [==============================] - 0s 176us/step - loss: 21.8254 - accuracy: 0.6114 - f1_m: 0.5920 - recall_m: 0.5850 - mcc_metric: 0.2342 - val_loss: 15.5009 - val_accuracy: 0.6917 - val_f1_m: 0.6433 - val_recall_m: 0.5633 - val_mcc_metric: 0.3883\n",
      "Epoch 42/50\n",
      "718/718 [==============================] - 0s 245us/step - loss: 34.5889 - accuracy: 0.6316 - f1_m: 0.5915 - recall_m: 0.6058 - mcc_metric: 0.3163 - val_loss: 23.0750 - val_accuracy: 0.6250 - val_f1_m: 0.4606 - val_recall_m: 0.3200 - val_mcc_metric: 0.3227\n",
      "Epoch 43/50\n",
      "718/718 [==============================] - 0s 254us/step - loss: 31.5921 - accuracy: 0.6031 - f1_m: 0.5484 - recall_m: 0.5646 - mcc_metric: 0.2301 - val_loss: 85.9853 - val_accuracy: 0.5111 - val_f1_m: 0.5233 - val_recall_m: 0.5233 - val_mcc_metric: 0.0467\n",
      "Epoch 44/50\n",
      "718/718 [==============================] - 0s 147us/step - loss: 38.8779 - accuracy: 0.6191 - f1_m: 0.6209 - recall_m: 0.6330 - mcc_metric: 0.2321 - val_loss: 58.1218 - val_accuracy: 0.5111 - val_f1_m: 0.5224 - val_recall_m: 0.5183 - val_mcc_metric: 0.0500\n",
      "Epoch 45/50\n",
      "718/718 [==============================] - 0s 139us/step - loss: 62.1820 - accuracy: 0.5891 - f1_m: 0.5500 - recall_m: 0.5290 - mcc_metric: 0.1822 - val_loss: 56.9997 - val_accuracy: 0.6167 - val_f1_m: 0.6266 - val_recall_m: 0.6600 - val_mcc_metric: 0.2107\n",
      "Epoch 46/50\n",
      "718/718 [==============================] - 0s 309us/step - loss: 44.2352 - accuracy: 0.6198 - f1_m: 0.6225 - recall_m: 0.6753 - mcc_metric: 0.2546 - val_loss: 36.4896 - val_accuracy: 0.6056 - val_f1_m: 0.6829 - val_recall_m: 0.8317 - val_mcc_metric: 0.2515\n",
      "Epoch 47/50\n",
      "718/718 [==============================] - 0s 251us/step - loss: 28.6207 - accuracy: 0.6309 - f1_m: 0.5936 - recall_m: 0.5763 - mcc_metric: 0.2604 - val_loss: 19.8657 - val_accuracy: 0.6333 - val_f1_m: 0.7111 - val_recall_m: 0.8933 - val_mcc_metric: 0.3256\n",
      "Epoch 48/50\n",
      "718/718 [==============================] - 0s 141us/step - loss: 9.5605 - accuracy: 0.6581 - f1_m: 0.6507 - recall_m: 0.6289 - mcc_metric: 0.3475 - val_loss: 6.6949 - val_accuracy: 0.6917 - val_f1_m: 0.6153 - val_recall_m: 0.4917 - val_mcc_metric: 0.4219\n",
      "Epoch 49/50\n",
      "718/718 [==============================] - 0s 164us/step - loss: 11.7039 - accuracy: 0.6351 - f1_m: 0.5822 - recall_m: 0.5564 - mcc_metric: 0.2864 - val_loss: 17.0416 - val_accuracy: 0.6861 - val_f1_m: 0.6877 - val_recall_m: 0.7017 - val_mcc_metric: 0.3620\n",
      "Epoch 50/50\n",
      "718/718 [==============================] - 0s 161us/step - loss: 18.8685 - accuracy: 0.6288 - f1_m: 0.6166 - recall_m: 0.6542 - mcc_metric: 0.2440 - val_loss: 5.4118 - val_accuracy: 0.7444 - val_f1_m: 0.7457 - val_recall_m: 0.7533 - val_mcc_metric: 0.4869\n",
      "CNN Error: 24.48%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50,verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[3]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 18, 12)            60        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 9, 12)             0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 108)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 21)                2289      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2)                 44        \n",
      "=================================================================\n",
      "Total params: 2,393\n",
      "Trainable params: 2,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss               Accuracy            F1 score             Recall              Mcc         \n",
      "[5.411756812201606, 0.7444444298744202, 0.7487008571624756, 0.7552083134651184, 0.49311110377311707]\n"
     ]
    }
   ],
   "source": [
    "print(\" Loss               Accuracy            F1 score             Recall              Mcc         \")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.31111037731171 %\n"
     ]
    }
   ],
   "source": [
    "mcc=scores[4]\n",
    "print(str(mcc*100)+str(\" %\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
