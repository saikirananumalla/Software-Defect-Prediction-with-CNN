{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>927.89</td>\n",
       "      <td>0.04</td>\n",
       "      <td>23.04</td>\n",
       "      <td>40.27</td>\n",
       "      <td>21378.61</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>769.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>14.86</td>\n",
       "      <td>51.81</td>\n",
       "      <td>11436.73</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>254.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.35</td>\n",
       "      <td>27.25</td>\n",
       "      <td>2381.95</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc   v(g)   ev(g)   iv(g)      n       v     l      d      i         e  \\\n",
       "0   1.1    1.4     1.4     1.4    1.3    1.30  1.30   1.30   1.30      1.30   \n",
       "1   1.0    1.0     1.0     1.0    1.0    1.00  1.00   1.00   1.00      1.00   \n",
       "2  83.0   11.0     1.0    11.0  171.0  927.89  0.04  23.04  40.27  21378.61   \n",
       "3  46.0    8.0     6.0     8.0  141.0  769.78  0.07  14.86  51.81  11436.73   \n",
       "4  25.0    3.0     1.0     3.0   58.0  254.75  0.11   9.35  27.25   2381.95   \n",
       "\n",
       "   ...   lOCode   lOComment   lOBlank   locCodeAndComment   uniq_Op  \\\n",
       "0  ...        2           2         2                   2       1.2   \n",
       "1  ...        1           1         1                   1       1.0   \n",
       "2  ...       65          10         6                   0      18.0   \n",
       "3  ...       37           2         5                   0      16.0   \n",
       "4  ...       21           0         2                   0      11.0   \n",
       "\n",
       "    uniq_Opnd   total_Op   total_Opnd   branchCount   defects   \n",
       "0         1.2        1.2          1.2           1.4      False  \n",
       "1         1.0        1.0          1.0           1.0       True  \n",
       "2        25.0      107.0         64.0          21.0       True  \n",
       "3        28.0       89.0         52.0          15.0       True  \n",
       "4        10.0       41.0         17.0           5.0       True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"dataset/KC1.csv\")\n",
    "data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>t</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2109.00000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.372262</td>\n",
       "      <td>2.838028</td>\n",
       "      <td>1.674443</td>\n",
       "      <td>2.546420</td>\n",
       "      <td>49.829445</td>\n",
       "      <td>258.696719</td>\n",
       "      <td>0.319583</td>\n",
       "      <td>6.771242</td>\n",
       "      <td>21.240071</td>\n",
       "      <td>5242.386240</td>\n",
       "      <td>...</td>\n",
       "      <td>291.24504</td>\n",
       "      <td>14.525367</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>1.759602</td>\n",
       "      <td>0.132764</td>\n",
       "      <td>7.631674</td>\n",
       "      <td>9.537316</td>\n",
       "      <td>31.043717</td>\n",
       "      <td>18.786724</td>\n",
       "      <td>4.665908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.754442</td>\n",
       "      <td>3.900763</td>\n",
       "      <td>2.200659</td>\n",
       "      <td>3.375859</td>\n",
       "      <td>83.599874</td>\n",
       "      <td>516.317605</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>7.863646</td>\n",
       "      <td>21.500367</td>\n",
       "      <td>17444.981211</td>\n",
       "      <td>...</td>\n",
       "      <td>969.16516</td>\n",
       "      <td>24.188302</td>\n",
       "      <td>3.085271</td>\n",
       "      <td>3.856850</td>\n",
       "      <td>0.704023</td>\n",
       "      <td>5.730347</td>\n",
       "      <td>12.195727</td>\n",
       "      <td>51.776056</td>\n",
       "      <td>32.074398</td>\n",
       "      <td>7.792206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>57.060000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>213.970000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.89000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>265.930000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>29.850000</td>\n",
       "      <td>2276.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>126.45000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>288.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>7918.820000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>193.060000</td>\n",
       "      <td>324803.510000</td>\n",
       "      <td>...</td>\n",
       "      <td>18044.64000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>678.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               loc         v(g)        ev(g)        iv(g)            n  \\\n",
       "count  2109.000000  2109.000000  2109.000000  2109.000000  2109.000000   \n",
       "mean     20.372262     2.838028     1.674443     2.546420    49.829445   \n",
       "std      29.754442     3.900763     2.200659     3.375859    83.599874   \n",
       "min       1.000000     1.000000     1.000000     1.000000     0.000000   \n",
       "25%       3.000000     1.000000     1.000000     1.000000     4.000000   \n",
       "50%       9.000000     1.000000     1.000000     1.000000    16.000000   \n",
       "75%      24.000000     3.000000     1.000000     3.000000    58.000000   \n",
       "max     288.000000    45.000000    26.000000    45.000000  1106.000000   \n",
       "\n",
       "                 v            l            d            i              e  ...  \\\n",
       "count  2109.000000  2109.000000  2109.000000  2109.000000    2109.000000  ...   \n",
       "mean    258.696719     0.319583     6.771242    21.240071    5242.386240  ...   \n",
       "std     516.317605     0.317029     7.863646    21.500367   17444.981211  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000       0.000000  ...   \n",
       "25%       8.000000     0.080000     1.500000     5.330000      12.000000  ...   \n",
       "50%      57.060000     0.200000     3.500000    14.400000     213.970000  ...   \n",
       "75%     265.930000     0.670000     9.200000    29.850000    2276.020000  ...   \n",
       "max    7918.820000     2.000000    53.750000   193.060000  324803.510000  ...   \n",
       "\n",
       "                 t       lOCode    lOComment      lOBlank   locCodeAndComment  \\\n",
       "count   2109.00000  2109.000000  2109.000000  2109.000000         2109.000000   \n",
       "mean     291.24504    14.525367     0.945946     1.759602            0.132764   \n",
       "std      969.16516    24.188302     3.085271     3.856850            0.704023   \n",
       "min        0.00000     0.000000     0.000000     0.000000            0.000000   \n",
       "25%        0.67000     0.000000     0.000000     0.000000            0.000000   \n",
       "50%       11.89000     5.000000     0.000000     0.000000            0.000000   \n",
       "75%      126.45000    17.000000     0.000000     2.000000            0.000000   \n",
       "max    18044.64000   262.000000    44.000000    58.000000           12.000000   \n",
       "\n",
       "           uniq_Op    uniq_Opnd     total_Op   total_Opnd   branchCount  \n",
       "count  2109.000000  2109.000000  2109.000000  2109.000000   2109.000000  \n",
       "mean      7.631674     9.537316    31.043717    18.786724      4.665908  \n",
       "std       5.730347    12.195727    51.776056    32.074398      7.792206  \n",
       "min       0.000000     0.000000     0.000000     0.000000      1.000000  \n",
       "25%       3.000000     1.000000     3.000000     1.000000      1.000000  \n",
       "50%       6.000000     5.000000    10.000000     6.000000      1.000000  \n",
       "75%      11.000000    13.000000    36.000000    22.000000      5.000000  \n",
       "max      37.000000   120.000000   678.000000   428.000000     89.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2109, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1, 1,\n",
       "       1, 1, 1.0, 1.0, 1.0, 1.0, 1.0, 1], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(2102):\n",
    "    if data2[i][21]==True:\n",
    "        data2[i][21]=1\n",
    "    else:\n",
    "        data2[i][21]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.1,   1.4,   1.4, ...,   1.2,   1.2,   1.4],\n",
       "       [  1. ,   1. ,   1. , ...,   1. ,   1. ,   1. ],\n",
       "       [ 83. ,  11. ,   1. , ..., 107. ,  64. ,  21. ],\n",
       "       ...,\n",
       "       [  2. ,   1. ,   1. , ...,   3. ,   1. ,   1. ],\n",
       "       [ 13. ,   1. ,   1. , ...,   9. ,   8. ,   1. ],\n",
       "       [ 11. ,   2. ,   1. , ...,  18. ,   9. ,   3. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3566, 21), (3566,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3566, 21, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "X_res=X_res.reshape(3566,21,1)\n",
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=1, kernel_size=3 , input_shape=(21,1),activation= 'relu' ))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(21, activation= 'relu' ))\n",
    "    model.add(Dense(num_classes, activation= 'sigmoid' ))\n",
    "# Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy' ,f1_m,recall_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2852 samples, validate on 714 samples\n",
      "Epoch 1/50\n",
      "2852/2852 [==============================] - 2s 796us/step - loss: 70.9072 - accuracy: 0.4691 - f1_m: 0.3042 - recall_m: 0.2357 - val_loss: 35.0449 - val_accuracy: 0.4342 - val_f1_m: 0.2047 - val_recall_m: 0.1463\n",
      "Epoch 2/50\n",
      "2852/2852 [==============================] - 0s 104us/step - loss: 23.5207 - accuracy: 0.4630 - f1_m: 0.3796 - recall_m: 0.3393 - val_loss: 2.3605 - val_accuracy: 0.5252 - val_f1_m: 0.5454 - val_recall_m: 0.5688\n",
      "Epoch 3/50\n",
      "2852/2852 [==============================] - 0s 155us/step - loss: 4.6942 - accuracy: 0.5202 - f1_m: 0.5832 - recall_m: 0.6639 - val_loss: 4.8054 - val_accuracy: 0.5721 - val_f1_m: 0.6063 - val_recall_m: 0.6579\n",
      "Epoch 4/50\n",
      "2852/2852 [==============================] - 0s 52us/step - loss: 4.9869 - accuracy: 0.5680 - f1_m: 0.6245 - recall_m: 0.7167 - val_loss: 3.7748 - val_accuracy: 0.5896 - val_f1_m: 0.6139 - val_recall_m: 0.6507\n",
      "Epoch 5/50\n",
      "2852/2852 [==============================] - 0s 67us/step - loss: 3.7366 - accuracy: 0.6008 - f1_m: 0.6420 - recall_m: 0.7128 - val_loss: 2.2078 - val_accuracy: 0.6541 - val_f1_m: 0.6620 - val_recall_m: 0.6761\n",
      "Epoch 6/50\n",
      "2852/2852 [==============================] - 0s 36us/step - loss: 2.4952 - accuracy: 0.6275 - f1_m: 0.6368 - recall_m: 0.6478 - val_loss: 1.3929 - val_accuracy: 0.6674 - val_f1_m: 0.6719 - val_recall_m: 0.6773\n",
      "Epoch 7/50\n",
      "2852/2852 [==============================] - 0s 22us/step - loss: 2.2664 - accuracy: 0.6311 - f1_m: 0.6394 - recall_m: 0.6488 - val_loss: 1.4496 - val_accuracy: 0.6758 - val_f1_m: 0.6800 - val_recall_m: 0.6870\n",
      "Epoch 8/50\n",
      "2852/2852 [==============================] - 0s 21us/step - loss: 1.9019 - accuracy: 0.6418 - f1_m: 0.6506 - recall_m: 0.6597 - val_loss: 1.4471 - val_accuracy: 0.6772 - val_f1_m: 0.6815 - val_recall_m: 0.6892\n",
      "Epoch 9/50\n",
      "2852/2852 [==============================] - 0s 19us/step - loss: 1.8024 - accuracy: 0.6408 - f1_m: 0.6508 - recall_m: 0.6606 - val_loss: 1.2349 - val_accuracy: 0.6821 - val_f1_m: 0.6838 - val_recall_m: 0.6870\n",
      "Epoch 10/50\n",
      "2852/2852 [==============================] - 0s 31us/step - loss: 1.5821 - accuracy: 0.6609 - f1_m: 0.6698 - recall_m: 0.6769 - val_loss: 0.9933 - val_accuracy: 0.7017 - val_f1_m: 0.7022 - val_recall_m: 0.7054\n",
      "Epoch 11/50\n",
      "2852/2852 [==============================] - 0s 26us/step - loss: 1.3104 - accuracy: 0.6622 - f1_m: 0.6675 - recall_m: 0.6770 - val_loss: 0.9678 - val_accuracy: 0.7115 - val_f1_m: 0.7060 - val_recall_m: 0.6998\n",
      "Epoch 12/50\n",
      "2852/2852 [==============================] - 0s 31us/step - loss: 1.0987 - accuracy: 0.6709 - f1_m: 0.6723 - recall_m: 0.6697 - val_loss: 0.8192 - val_accuracy: 0.7213 - val_f1_m: 0.7029 - val_recall_m: 0.6645\n",
      "Epoch 13/50\n",
      "2852/2852 [==============================] - 0s 21us/step - loss: 1.0431 - accuracy: 0.6907 - f1_m: 0.6835 - recall_m: 0.6678 - val_loss: 0.8133 - val_accuracy: 0.6036 - val_f1_m: 0.4085 - val_recall_m: 0.2758\n",
      "Epoch 14/50\n",
      "2852/2852 [==============================] - 0s 22us/step - loss: 0.8504 - accuracy: 0.6748 - f1_m: 0.6515 - recall_m: 0.6119 - val_loss: 0.6543 - val_accuracy: 0.7010 - val_f1_m: 0.6400 - val_recall_m: 0.5375\n",
      "Epoch 15/50\n",
      "2852/2852 [==============================] - 0s 21us/step - loss: 0.7605 - accuracy: 0.6597 - f1_m: 0.6284 - recall_m: 0.5810 - val_loss: 0.6291 - val_accuracy: 0.6450 - val_f1_m: 0.5399 - val_recall_m: 0.4221\n",
      "Epoch 16/50\n",
      "2852/2852 [==============================] - 0s 21us/step - loss: 0.7334 - accuracy: 0.6702 - f1_m: 0.6586 - recall_m: 0.6281 - val_loss: 0.6633 - val_accuracy: 0.7003 - val_f1_m: 0.6633 - val_recall_m: 0.5969\n",
      "Epoch 17/50\n",
      "2852/2852 [==============================] - 0s 21us/step - loss: 0.6952 - accuracy: 0.6702 - f1_m: 0.6515 - recall_m: 0.6185 - val_loss: 0.6494 - val_accuracy: 0.6120 - val_f1_m: 0.5068 - val_recall_m: 0.3993\n",
      "Epoch 18/50\n",
      "2852/2852 [==============================] - 0s 20us/step - loss: 0.7085 - accuracy: 0.6706 - f1_m: 0.6537 - recall_m: 0.6316 - val_loss: 0.6210 - val_accuracy: 0.6751 - val_f1_m: 0.6269 - val_recall_m: 0.5509\n",
      "Epoch 19/50\n",
      "2852/2852 [==============================] - 0s 20us/step - loss: 0.6850 - accuracy: 0.6687 - f1_m: 0.6539 - recall_m: 0.6250 - val_loss: 0.6064 - val_accuracy: 0.6779 - val_f1_m: 0.6393 - val_recall_m: 0.5775\n",
      "Epoch 20/50\n",
      "2852/2852 [==============================] - 0s 20us/step - loss: 0.7083 - accuracy: 0.6722 - f1_m: 0.6672 - recall_m: 0.6635 - val_loss: 0.6700 - val_accuracy: 0.7052 - val_f1_m: 0.7041 - val_recall_m: 0.7061\n",
      "Epoch 21/50\n",
      "2852/2852 [==============================] - 0s 20us/step - loss: 0.6577 - accuracy: 0.6650 - f1_m: 0.6584 - recall_m: 0.6412 - val_loss: 0.6151 - val_accuracy: 0.6926 - val_f1_m: 0.6686 - val_recall_m: 0.6285\n",
      "Epoch 22/50\n",
      "2852/2852 [==============================] - 0s 21us/step - loss: 0.6658 - accuracy: 0.6748 - f1_m: 0.6613 - recall_m: 0.6413 - val_loss: 0.6065 - val_accuracy: 0.6842 - val_f1_m: 0.6583 - val_recall_m: 0.6188\n",
      "Epoch 23/50\n",
      "2852/2852 [==============================] - 0s 22us/step - loss: 0.6396 - accuracy: 0.6552 - f1_m: 0.6506 - recall_m: 0.6304 - val_loss: 0.6054 - val_accuracy: 0.6779 - val_f1_m: 0.6444 - val_recall_m: 0.5910\n",
      "Epoch 24/50\n",
      "2852/2852 [==============================] - 0s 120us/step - loss: 0.6559 - accuracy: 0.6678 - f1_m: 0.6587 - recall_m: 0.6402 - val_loss: 0.6076 - val_accuracy: 0.6639 - val_f1_m: 0.6338 - val_recall_m: 0.5900\n",
      "Epoch 25/50\n",
      "2852/2852 [==============================] - 0s 84us/step - loss: 0.6288 - accuracy: 0.6613 - f1_m: 0.6467 - recall_m: 0.6264 - val_loss: 0.6021 - val_accuracy: 0.6919 - val_f1_m: 0.6667 - val_recall_m: 0.6272\n",
      "Epoch 26/50\n",
      "2852/2852 [==============================] - 0s 60us/step - loss: 0.6246 - accuracy: 0.6744 - f1_m: 0.6651 - recall_m: 0.6438 - val_loss: 0.6065 - val_accuracy: 0.6982 - val_f1_m: 0.6794 - val_recall_m: 0.6448\n",
      "Epoch 27/50\n",
      "2852/2852 [==============================] - 0s 65us/step - loss: 0.6496 - accuracy: 0.6806 - f1_m: 0.6787 - recall_m: 0.6700 - val_loss: 0.5970 - val_accuracy: 0.6940 - val_f1_m: 0.6768 - val_recall_m: 0.6498\n",
      "Epoch 28/50\n",
      "2852/2852 [==============================] - 0s 84us/step - loss: 0.6901 - accuracy: 0.6736 - f1_m: 0.6671 - recall_m: 0.6614 - val_loss: 0.6330 - val_accuracy: 0.7066 - val_f1_m: 0.6961 - val_recall_m: 0.6760\n",
      "Epoch 29/50\n",
      "2852/2852 [==============================] - 0s 107us/step - loss: 0.6659 - accuracy: 0.6783 - f1_m: 0.6707 - recall_m: 0.6695 - val_loss: 0.6034 - val_accuracy: 0.6933 - val_f1_m: 0.6742 - val_recall_m: 0.6441\n",
      "Epoch 30/50\n",
      "2852/2852 [==============================] - ETA: 0s - loss: 0.6562 - accuracy: 0.6530 - f1_m: 0.6411 - recall_m: 0.62 - 0s 92us/step - loss: 0.6553 - accuracy: 0.6545 - f1_m: 0.6467 - recall_m: 0.6271 - val_loss: 0.6565 - val_accuracy: 0.7080 - val_f1_m: 0.7010 - val_recall_m: 0.6864\n",
      "Epoch 31/50\n",
      "2852/2852 [==============================] - 0s 89us/step - loss: 0.6847 - accuracy: 0.6815 - f1_m: 0.6751 - recall_m: 0.6740 - val_loss: 0.6334 - val_accuracy: 0.6008 - val_f1_m: 0.5645 - val_recall_m: 0.5268\n",
      "Epoch 32/50\n",
      "2852/2852 [==============================] - 0s 100us/step - loss: 0.6919 - accuracy: 0.6716 - f1_m: 0.6593 - recall_m: 0.6537 - val_loss: 0.6933 - val_accuracy: 0.5945 - val_f1_m: 0.6528 - val_recall_m: 0.7636\n",
      "Epoch 33/50\n",
      "2852/2852 [==============================] - 0s 133us/step - loss: 0.6848 - accuracy: 0.6722 - f1_m: 0.6592 - recall_m: 0.6613 - val_loss: 0.6777 - val_accuracy: 0.5903 - val_f1_m: 0.6465 - val_recall_m: 0.7505\n",
      "Epoch 34/50\n",
      "2852/2852 [==============================] - 0s 146us/step - loss: 0.6870 - accuracy: 0.6734 - f1_m: 0.6783 - recall_m: 0.6827 - val_loss: 0.7177 - val_accuracy: 0.7059 - val_f1_m: 0.6675 - val_recall_m: 0.5966\n",
      "Epoch 35/50\n",
      "2852/2852 [==============================] - 0s 103us/step - loss: 0.7551 - accuracy: 0.6797 - f1_m: 0.6544 - recall_m: 0.6329 - val_loss: 0.6805 - val_accuracy: 0.7164 - val_f1_m: 0.7119 - val_recall_m: 0.7020\n",
      "Epoch 36/50\n",
      "2852/2852 [==============================] - 0s 85us/step - loss: 0.7569 - accuracy: 0.6827 - f1_m: 0.6721 - recall_m: 0.6614 - val_loss: 0.7251 - val_accuracy: 0.5980 - val_f1_m: 0.6582 - val_recall_m: 0.7742\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2852/2852 [==============================] - 0s 109us/step - loss: 0.7094 - accuracy: 0.6643 - f1_m: 0.6701 - recall_m: 0.6823 - val_loss: 0.6923 - val_accuracy: 0.5707 - val_f1_m: 0.5047 - val_recall_m: 0.4409\n",
      "Epoch 38/50\n",
      "2852/2852 [==============================] - 0s 121us/step - loss: 0.6790 - accuracy: 0.6501 - f1_m: 0.6559 - recall_m: 0.6657 - val_loss: 0.6638 - val_accuracy: 0.7129 - val_f1_m: 0.7068 - val_recall_m: 0.6936\n",
      "Epoch 39/50\n",
      "2852/2852 [==============================] - 0s 126us/step - loss: 0.7887 - accuracy: 0.6785 - f1_m: 0.6684 - recall_m: 0.6519 - val_loss: 0.8097 - val_accuracy: 0.6169 - val_f1_m: 0.4660 - val_recall_m: 0.3368\n",
      "Epoch 40/50\n",
      "2852/2852 [==============================] - 0s 84us/step - loss: 0.7059 - accuracy: 0.6715 - f1_m: 0.6602 - recall_m: 0.6546 - val_loss: 0.6449 - val_accuracy: 0.6120 - val_f1_m: 0.6762 - val_recall_m: 0.8058\n",
      "Epoch 41/50\n",
      "2852/2852 [==============================] - 0s 49us/step - loss: 0.6583 - accuracy: 0.6811 - f1_m: 0.6788 - recall_m: 0.6708 - val_loss: 0.6276 - val_accuracy: 0.7024 - val_f1_m: 0.6885 - val_recall_m: 0.6598\n",
      "Epoch 42/50\n",
      "2852/2852 [==============================] - 0s 19us/step - loss: 0.7178 - accuracy: 0.6829 - f1_m: 0.6802 - recall_m: 0.6953 - val_loss: 0.6864 - val_accuracy: 0.5812 - val_f1_m: 0.5022 - val_recall_m: 0.4262\n",
      "Epoch 43/50\n",
      "2852/2852 [==============================] - 0s 20us/step - loss: 0.6674 - accuracy: 0.6678 - f1_m: 0.6714 - recall_m: 0.6767 - val_loss: 0.6106 - val_accuracy: 0.6835 - val_f1_m: 0.7050 - val_recall_m: 0.7627\n",
      "Epoch 44/50\n",
      "2852/2852 [==============================] - 0s 19us/step - loss: 0.6613 - accuracy: 0.6653 - f1_m: 0.6687 - recall_m: 0.6848 - val_loss: 0.6513 - val_accuracy: 0.7059 - val_f1_m: 0.7166 - val_recall_m: 0.7480\n",
      "Epoch 45/50\n",
      "2852/2852 [==============================] - 0s 21us/step - loss: 0.6535 - accuracy: 0.6732 - f1_m: 0.6728 - recall_m: 0.6778 - val_loss: 0.6389 - val_accuracy: 0.7059 - val_f1_m: 0.7079 - val_recall_m: 0.7126\n",
      "Epoch 46/50\n",
      "2852/2852 [==============================] - 0s 26us/step - loss: 0.6812 - accuracy: 0.6799 - f1_m: 0.6787 - recall_m: 0.6853 - val_loss: 0.5961 - val_accuracy: 0.6954 - val_f1_m: 0.7013 - val_recall_m: 0.7217\n",
      "Epoch 47/50\n",
      "2852/2852 [==============================] - 0s 33us/step - loss: 0.6825 - accuracy: 0.6737 - f1_m: 0.6792 - recall_m: 0.6936 - val_loss: 0.6660 - val_accuracy: 0.6008 - val_f1_m: 0.5051 - val_recall_m: 0.4102\n",
      "Epoch 48/50\n",
      "2852/2852 [==============================] - 0s 24us/step - loss: 0.6526 - accuracy: 0.6674 - f1_m: 0.6620 - recall_m: 0.6724 - val_loss: 0.5987 - val_accuracy: 0.6968 - val_f1_m: 0.7048 - val_recall_m: 0.7301\n",
      "Epoch 49/50\n",
      "2852/2852 [==============================] - 0s 22us/step - loss: 0.6415 - accuracy: 0.6786 - f1_m: 0.6795 - recall_m: 0.6817 - val_loss: 0.6072 - val_accuracy: 0.7045 - val_f1_m: 0.7143 - val_recall_m: 0.7417\n",
      "Epoch 50/50\n",
      "2852/2852 [==============================] - 0s 50us/step - loss: 0.6322 - accuracy: 0.6844 - f1_m: 0.6827 - recall_m: 0.6877 - val_loss: 0.6357 - val_accuracy: 0.5672 - val_f1_m: 0.5022 - val_recall_m: 0.4396\n",
      "CNN Error: 43.28%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200,verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.940170990485771, 0.7135854363441467, 0.7218640446662903, 0.7529891729354858]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
