{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>lOCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>problems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>8411.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.53</td>\n",
       "      <td>81.24</td>\n",
       "      <td>870848.58</td>\n",
       "      <td>...</td>\n",
       "      <td>359</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>47.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>3732.82</td>\n",
       "      <td>0.03</td>\n",
       "      <td>39.82</td>\n",
       "      <td>93.74</td>\n",
       "      <td>148644.06</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3123.96</td>\n",
       "      <td>0.03</td>\n",
       "      <td>29.48</td>\n",
       "      <td>105.96</td>\n",
       "      <td>92103.07</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc   v(g)   ev(g)   iv(g)       n        v     l       d       i  \\\n",
       "0    1.1    1.4     1.4     1.4     1.3     1.30  1.30    1.30    1.30   \n",
       "1    1.0    1.0     1.0     1.0     1.0     1.00  1.00    1.00    1.00   \n",
       "2  415.0   59.0    50.0    51.0  1159.0  8411.31  0.01  103.53   81.24   \n",
       "3  230.0   33.0    10.0    16.0   575.0  3732.82  0.03   39.82   93.74   \n",
       "4  175.0   26.0    12.0    13.0   500.0  3123.96  0.03   29.48  105.96   \n",
       "\n",
       "           e  ...   lOCode   lOComment   lOBlank   lOCodeAndComment   uniq_Op  \\\n",
       "0       1.30  ...        2           2         2                  2       1.2   \n",
       "1       1.00  ...        1           1         1                  1       1.0   \n",
       "2  870848.58  ...      359          35         9                 10      47.0   \n",
       "3  148644.06  ...      174          15        34                  5      23.0   \n",
       "4   92103.07  ...      142           7        19                  4      18.0   \n",
       "\n",
       "    uniq_Opnd   total_Op   total_Opnd   branchCount   problems   \n",
       "0         1.2        1.2          1.2           1.4          no  \n",
       "1         1.0        1.0          1.0           1.0         yes  \n",
       "2       106.0      692.0        467.0         106.0         yes  \n",
       "3        67.0      343.0        232.0          65.0         yes  \n",
       "4        58.0      310.0        190.0          51.0         yes  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"dataset/KC2.csv\")\n",
    "data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>t</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>lOCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>5.220000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.894828</td>\n",
       "      <td>4.893487</td>\n",
       "      <td>2.447126</td>\n",
       "      <td>3.650192</td>\n",
       "      <td>94.630843</td>\n",
       "      <td>555.472644</td>\n",
       "      <td>0.274464</td>\n",
       "      <td>9.735287</td>\n",
       "      <td>28.320441</td>\n",
       "      <td>1.854299e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1094.811456</td>\n",
       "      <td>27.772031</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.339080</td>\n",
       "      <td>0.281609</td>\n",
       "      <td>9.197701</td>\n",
       "      <td>14.465900</td>\n",
       "      <td>57.611494</td>\n",
       "      <td>37.023372</td>\n",
       "      <td>8.765134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.944048</td>\n",
       "      <td>10.976772</td>\n",
       "      <td>6.665003</td>\n",
       "      <td>8.054860</td>\n",
       "      <td>233.230165</td>\n",
       "      <td>1817.468320</td>\n",
       "      <td>0.275609</td>\n",
       "      <td>11.088640</td>\n",
       "      <td>32.225597</td>\n",
       "      <td>1.132712e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>7556.521581</td>\n",
       "      <td>64.431485</td>\n",
       "      <td>5.582052</td>\n",
       "      <td>9.214753</td>\n",
       "      <td>1.038236</td>\n",
       "      <td>6.360180</td>\n",
       "      <td>22.086661</td>\n",
       "      <td>142.990741</td>\n",
       "      <td>90.398620</td>\n",
       "      <td>21.942779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.610000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>7.740000</td>\n",
       "      <td>1.741000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>109.205000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.560000</td>\n",
       "      <td>6.135900e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>34.090000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>104.750000</td>\n",
       "      <td>543.787500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>14.610000</td>\n",
       "      <td>38.365000</td>\n",
       "      <td>7.624085e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>423.562500</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1275.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>33814.560000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>103.530000</td>\n",
       "      <td>415.060000</td>\n",
       "      <td>2.147484e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>153047.010000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>2469.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>361.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               loc        v(g)       ev(g)       iv(g)            n  \\\n",
       "count   522.000000  522.000000  522.000000  522.000000   522.000000   \n",
       "mean     36.894828    4.893487    2.447126    3.650192    94.630843   \n",
       "std      77.944048   10.976772    6.665003    8.054860   233.230165   \n",
       "min       1.000000    1.000000    1.000000    1.000000     1.000000   \n",
       "25%       4.000000    1.000000    1.000000    1.000000     5.000000   \n",
       "50%      13.000000    2.000000    1.000000    2.000000    27.000000   \n",
       "75%      45.000000    5.000000    1.000000    4.000000   104.750000   \n",
       "max    1275.000000  180.000000  125.000000  143.000000  3982.000000   \n",
       "\n",
       "                  v           l           d           i             e  ...  \\\n",
       "count    522.000000  522.000000  522.000000  522.000000  5.220000e+02  ...   \n",
       "mean     555.472644    0.274464    9.735287   28.320441  1.854299e+04  ...   \n",
       "std     1817.468320    0.275609   11.088640   32.225597  1.132712e+05  ...   \n",
       "min        0.000000    0.000000    0.000000    0.000000  0.000000e+00  ...   \n",
       "25%       11.610000    0.060000    1.500000    7.740000  1.741000e+01  ...   \n",
       "50%      109.205000    0.140000    6.000000   20.560000  6.135900e+02  ...   \n",
       "75%      543.787500    0.500000   14.610000   38.365000  7.624085e+03  ...   \n",
       "max    33814.560000    2.000000  103.530000  415.060000  2.147484e+06  ...   \n",
       "\n",
       "                   t       lOCode   lOComment     lOBlank   lOCodeAndComment  \\\n",
       "count     522.000000   522.000000  522.000000  522.000000         522.000000   \n",
       "mean     1094.811456    27.772031    2.000000    4.339080           0.281609   \n",
       "std      7556.521581    64.431485    5.582052    9.214753           1.038236   \n",
       "min         0.000000     0.000000    0.000000    0.000000           0.000000   \n",
       "25%         0.970000     2.000000    0.000000    0.000000           0.000000   \n",
       "50%        34.090000     8.000000    0.000000    1.000000           0.000000   \n",
       "75%       423.562500    33.750000    2.000000    5.000000           0.000000   \n",
       "max    153047.010000  1107.000000   44.000000  121.000000          11.000000   \n",
       "\n",
       "          uniq_Op   uniq_Opnd     total_Op   total_Opnd   branchCount  \n",
       "count  522.000000  522.000000   522.000000   522.000000    522.000000  \n",
       "mean     9.197701   14.465900    57.611494    37.023372      8.765134  \n",
       "std      6.360180   22.086661   142.990741    90.398620     21.942779  \n",
       "min      1.000000    0.000000     1.000000     0.000000      1.000000  \n",
       "25%      3.000000    2.000000     4.000000     2.000000      1.000000  \n",
       "50%      8.000000    7.000000    16.500000    11.000000      3.000000  \n",
       "75%     14.000000   20.000000    64.000000    41.000000      9.000000  \n",
       "max     47.000000  325.000000  2469.000000  1513.000000    361.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 22)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1, 1,\n",
       "       1, 1, 1.0, 1.0, 1.0, 1.0, 1.0, 1], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(522):\n",
    "    if data2[i][21]=='yes':\n",
    "        data2[i][21]=1\n",
    "    else:\n",
    "        data2[i][21]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.1,   1.4,   1.4, ...,   1.2,   1.2,   1.4],\n",
       "       [  1. ,   1. ,   1. , ...,   1. ,   1. ,   1. ],\n",
       "       [415. ,  59. ,  50. , ..., 692. , 467. , 106. ],\n",
       "       ...,\n",
       "       [  4. ,   1. ,   1. , ...,   3. ,   1. ,   1. ],\n",
       "       [  4. ,   1. ,   1. , ...,   3. ,   2. ,   1. ],\n",
       "       [  3. ,   1. ,   1. , ...,   1. ,   0. ,   1. ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((830, 21), (830,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 21, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "X_res=X_res.reshape(830,21,1)\n",
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=1, kernel_size=3 , input_shape=(21,1),activation= 'relu' ))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(21, activation= 'relu' ))\n",
    "    model.add(Dense(num_classes, activation= 'sigmoid' ))\n",
    "# Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy' ,f1_m,recall_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 664 samples, validate on 166 samples\n",
      "Epoch 1/50\n",
      "664/664 [==============================] - 1s 2ms/step - loss: 645.3407 - accuracy: 0.4887 - f1_m: 0.2854 - recall_m: 0.2139 - val_loss: 1121.4352 - val_accuracy: 0.5151 - val_f1_m: 0.2780 - val_recall_m: 0.1867\n",
      "Epoch 2/50\n",
      "664/664 [==============================] - 0s 164us/step - loss: 564.6853 - accuracy: 0.4880 - f1_m: 0.3407 - recall_m: 0.2631 - val_loss: 1033.9014 - val_accuracy: 0.5181 - val_f1_m: 0.2920 - val_recall_m: 0.1988\n",
      "Epoch 3/50\n",
      "664/664 [==============================] - 0s 134us/step - loss: 547.6835 - accuracy: 0.5045 - f1_m: 0.3705 - recall_m: 0.2908 - val_loss: 947.4221 - val_accuracy: 0.5241 - val_f1_m: 0.3190 - val_recall_m: 0.2229\n",
      "Epoch 4/50\n",
      "664/664 [==============================] - 0s 151us/step - loss: 477.1123 - accuracy: 0.5053 - f1_m: 0.3741 - recall_m: 0.2952 - val_loss: 865.3881 - val_accuracy: 0.5030 - val_f1_m: 0.3154 - val_recall_m: 0.2289\n",
      "Epoch 5/50\n",
      "664/664 [==============================] - 0s 141us/step - loss: 339.6152 - accuracy: 0.4902 - f1_m: 0.3797 - recall_m: 0.3095 - val_loss: 789.9122 - val_accuracy: 0.5030 - val_f1_m: 0.3154 - val_recall_m: 0.2289\n",
      "Epoch 6/50\n",
      "664/664 [==============================] - 0s 163us/step - loss: 407.0043 - accuracy: 0.4970 - f1_m: 0.3735 - recall_m: 0.3041 - val_loss: 716.1954 - val_accuracy: 0.5000 - val_f1_m: 0.3140 - val_recall_m: 0.2289\n",
      "Epoch 7/50\n",
      "664/664 [==============================] - 0s 61us/step - loss: 357.4287 - accuracy: 0.4804 - f1_m: 0.3778 - recall_m: 0.3144 - val_loss: 648.4225 - val_accuracy: 0.5120 - val_f1_m: 0.3415 - val_recall_m: 0.2530\n",
      "Epoch 8/50\n",
      "664/664 [==============================] - 0s 92us/step - loss: 335.9906 - accuracy: 0.4789 - f1_m: 0.3930 - recall_m: 0.3392 - val_loss: 584.5448 - val_accuracy: 0.5151 - val_f1_m: 0.3482 - val_recall_m: 0.2590\n",
      "Epoch 9/50\n",
      "664/664 [==============================] - 0s 128us/step - loss: 284.5809 - accuracy: 0.4887 - f1_m: 0.4066 - recall_m: 0.3534 - val_loss: 526.4911 - val_accuracy: 0.5181 - val_f1_m: 0.3548 - val_recall_m: 0.2651\n",
      "Epoch 10/50\n",
      "664/664 [==============================] - 0s 89us/step - loss: 191.2967 - accuracy: 0.4887 - f1_m: 0.4060 - recall_m: 0.3502 - val_loss: 472.0006 - val_accuracy: 0.5030 - val_f1_m: 0.3478 - val_recall_m: 0.2651\n",
      "Epoch 11/50\n",
      "664/664 [==============================] - 0s 70us/step - loss: 224.4016 - accuracy: 0.4895 - f1_m: 0.4205 - recall_m: 0.3742 - val_loss: 422.8313 - val_accuracy: 0.5000 - val_f1_m: 0.3465 - val_recall_m: 0.2651\n",
      "Epoch 12/50\n",
      "664/664 [==============================] - 0s 94us/step - loss: 204.3687 - accuracy: 0.4962 - f1_m: 0.4423 - recall_m: 0.4002 - val_loss: 378.2958 - val_accuracy: 0.5060 - val_f1_m: 0.3643 - val_recall_m: 0.2831\n",
      "Epoch 13/50\n",
      "664/664 [==============================] - 0s 70us/step - loss: 195.8405 - accuracy: 0.5068 - f1_m: 0.4479 - recall_m: 0.4002 - val_loss: 337.3272 - val_accuracy: 0.5090 - val_f1_m: 0.3707 - val_recall_m: 0.2892\n",
      "Epoch 14/50\n",
      "664/664 [==============================] - 0s 55us/step - loss: 175.4452 - accuracy: 0.5090 - f1_m: 0.4675 - recall_m: 0.4336 - val_loss: 299.7195 - val_accuracy: 0.5090 - val_f1_m: 0.3707 - val_recall_m: 0.2892\n",
      "Epoch 15/50\n",
      "664/664 [==============================] - 0s 100us/step - loss: 140.2590 - accuracy: 0.5120 - f1_m: 0.4710 - recall_m: 0.4355 - val_loss: 264.5571 - val_accuracy: 0.5181 - val_f1_m: 0.3846 - val_recall_m: 0.3012\n",
      "Epoch 16/50\n",
      "664/664 [==============================] - 0s 125us/step - loss: 95.7594 - accuracy: 0.5105 - f1_m: 0.4748 - recall_m: 0.4438 - val_loss: 234.7366 - val_accuracy: 0.5151 - val_f1_m: 0.4059 - val_recall_m: 0.3313\n",
      "Epoch 17/50\n",
      "664/664 [==============================] - 0s 104us/step - loss: 90.1441 - accuracy: 0.5188 - f1_m: 0.5106 - recall_m: 0.5011 - val_loss: 208.9750 - val_accuracy: 0.3765 - val_f1_m: 0.4509 - val_recall_m: 0.5120\n",
      "Epoch 18/50\n",
      "664/664 [==============================] - 0s 159us/step - loss: 81.5897 - accuracy: 0.4744 - f1_m: 0.5310 - recall_m: 0.5888 - val_loss: 185.5569 - val_accuracy: 0.5000 - val_f1_m: 0.4196 - val_recall_m: 0.3614\n",
      "Epoch 19/50\n",
      "664/664 [==============================] - 0s 194us/step - loss: 84.4388 - accuracy: 0.5151 - f1_m: 0.5017 - recall_m: 0.4872 - val_loss: 163.8136 - val_accuracy: 0.5030 - val_f1_m: 0.4086 - val_recall_m: 0.3434\n",
      "Epoch 20/50\n",
      "664/664 [==============================] - 0s 158us/step - loss: 73.0157 - accuracy: 0.5143 - f1_m: 0.5003 - recall_m: 0.4878 - val_loss: 144.6907 - val_accuracy: 0.4970 - val_f1_m: 0.4099 - val_recall_m: 0.3494\n",
      "Epoch 21/50\n",
      "664/664 [==============================] - 0s 224us/step - loss: 71.4843 - accuracy: 0.5128 - f1_m: 0.4924 - recall_m: 0.4731 - val_loss: 126.4930 - val_accuracy: 0.4940 - val_f1_m: 0.4167 - val_recall_m: 0.3614\n",
      "Epoch 22/50\n",
      "664/664 [==============================] - 0s 118us/step - loss: 57.4666 - accuracy: 0.5151 - f1_m: 0.5110 - recall_m: 0.5152 - val_loss: 109.9162 - val_accuracy: 0.5181 - val_f1_m: 0.4631 - val_recall_m: 0.4157\n",
      "Epoch 23/50\n",
      "664/664 [==============================] - 0s 107us/step - loss: 47.3341 - accuracy: 0.5324 - f1_m: 0.5515 - recall_m: 0.5806 - val_loss: 94.0263 - val_accuracy: 0.4066 - val_f1_m: 0.4632 - val_recall_m: 0.5120\n",
      "Epoch 24/50\n",
      "664/664 [==============================] - 0s 103us/step - loss: 43.6765 - accuracy: 0.5196 - f1_m: 0.5453 - recall_m: 0.5839 - val_loss: 79.5676 - val_accuracy: 0.5181 - val_f1_m: 0.4631 - val_recall_m: 0.4157\n",
      "Epoch 25/50\n",
      "664/664 [==============================] - 0s 172us/step - loss: 38.0093 - accuracy: 0.5218 - f1_m: 0.5243 - recall_m: 0.5316 - val_loss: 66.8698 - val_accuracy: 0.5151 - val_f1_m: 0.4542 - val_recall_m: 0.4036\n",
      "Epoch 26/50\n",
      "664/664 [==============================] - 0s 110us/step - loss: 31.6877 - accuracy: 0.5188 - f1_m: 0.5170 - recall_m: 0.5136 - val_loss: 55.2088 - val_accuracy: 0.5120 - val_f1_m: 0.4564 - val_recall_m: 0.4096\n",
      "Epoch 27/50\n",
      "664/664 [==============================] - 0s 156us/step - loss: 26.2947 - accuracy: 0.5181 - f1_m: 0.5159 - recall_m: 0.5117 - val_loss: 44.8421 - val_accuracy: 0.5181 - val_f1_m: 0.4702 - val_recall_m: 0.4277\n",
      "Epoch 28/50\n",
      "664/664 [==============================] - 0s 224us/step - loss: 21.0085 - accuracy: 0.5264 - f1_m: 0.5201 - recall_m: 0.5230 - val_loss: 34.8073 - val_accuracy: 0.5241 - val_f1_m: 0.4936 - val_recall_m: 0.4639\n",
      "Epoch 29/50\n",
      "664/664 [==============================] - 0s 175us/step - loss: 15.2139 - accuracy: 0.5271 - f1_m: 0.5464 - recall_m: 0.5731 - val_loss: 26.2734 - val_accuracy: 0.5241 - val_f1_m: 0.5062 - val_recall_m: 0.4880\n",
      "Epoch 30/50\n",
      "664/664 [==============================] - 0s 214us/step - loss: 9.6378 - accuracy: 0.5286 - f1_m: 0.5587 - recall_m: 0.5952 - val_loss: 19.0450 - val_accuracy: 0.5120 - val_f1_m: 0.5031 - val_recall_m: 0.4940\n",
      "Epoch 31/50\n",
      "664/664 [==============================] - 0s 124us/step - loss: 8.4805 - accuracy: 0.5286 - f1_m: 0.5478 - recall_m: 0.5722 - val_loss: 12.1282 - val_accuracy: 0.5271 - val_f1_m: 0.5169 - val_recall_m: 0.5060\n",
      "Epoch 32/50\n",
      "664/664 [==============================] - 0s 203us/step - loss: 5.0485 - accuracy: 0.5166 - f1_m: 0.5504 - recall_m: 0.5922 - val_loss: 5.4226 - val_accuracy: 0.5120 - val_f1_m: 0.5120 - val_recall_m: 0.5120\n",
      "Epoch 33/50\n",
      "664/664 [==============================] - 0s 158us/step - loss: 1.9723 - accuracy: 0.5128 - f1_m: 0.5671 - recall_m: 0.6364 - val_loss: 0.5590 - val_accuracy: 0.6536 - val_f1_m: 0.7268 - val_recall_m: 0.9217\n",
      "Epoch 34/50\n",
      "664/664 [==============================] - 0s 246us/step - loss: 0.6930 - accuracy: 0.6039 - f1_m: 0.6961 - recall_m: 0.9117 - val_loss: 0.5933 - val_accuracy: 0.6596 - val_f1_m: 0.7341 - val_recall_m: 0.9398\n",
      "Epoch 35/50\n",
      "664/664 [==============================] - 0s 139us/step - loss: 0.8394 - accuracy: 0.5979 - f1_m: 0.6938 - recall_m: 0.9217 - val_loss: 0.6578 - val_accuracy: 0.6446 - val_f1_m: 0.7318 - val_recall_m: 0.9699\n",
      "Epoch 36/50\n",
      "664/664 [==============================] - 0s 211us/step - loss: 0.9660 - accuracy: 0.5926 - f1_m: 0.7023 - recall_m: 0.9444 - val_loss: 0.6814 - val_accuracy: 0.6536 - val_f1_m: 0.7344 - val_recall_m: 0.9578\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 0s 142us/step - loss: 1.0396 - accuracy: 0.5994 - f1_m: 0.7024 - recall_m: 0.9320 - val_loss: 0.6888 - val_accuracy: 0.6506 - val_f1_m: 0.7302 - val_recall_m: 0.9458\n",
      "Epoch 38/50\n",
      "664/664 [==============================] - 0s 193us/step - loss: 1.0420 - accuracy: 0.6002 - f1_m: 0.6935 - recall_m: 0.9164 - val_loss: 0.6902 - val_accuracy: 0.6476 - val_f1_m: 0.7273 - val_recall_m: 0.9398\n",
      "Epoch 39/50\n",
      "664/664 [==============================] - 0s 114us/step - loss: 1.0602 - accuracy: 0.6032 - f1_m: 0.7040 - recall_m: 0.9384 - val_loss: 0.6955 - val_accuracy: 0.6536 - val_f1_m: 0.7344 - val_recall_m: 0.9578\n",
      "Epoch 40/50\n",
      "664/664 [==============================] - 0s 101us/step - loss: 0.9848 - accuracy: 0.6039 - f1_m: 0.7001 - recall_m: 0.9281 - val_loss: 0.6795 - val_accuracy: 0.6506 - val_f1_m: 0.7290 - val_recall_m: 0.9398\n",
      "Epoch 41/50\n",
      "664/664 [==============================] - 0s 117us/step - loss: 1.0283 - accuracy: 0.6107 - f1_m: 0.6948 - recall_m: 0.9100 - val_loss: 0.6711 - val_accuracy: 0.6536 - val_f1_m: 0.7307 - val_recall_m: 0.9398\n",
      "Epoch 42/50\n",
      "664/664 [==============================] - 0s 165us/step - loss: 1.0285 - accuracy: 0.6092 - f1_m: 0.6964 - recall_m: 0.9167 - val_loss: 0.6682 - val_accuracy: 0.6596 - val_f1_m: 0.7378 - val_recall_m: 0.9578\n",
      "Epoch 43/50\n",
      "664/664 [==============================] - 0s 183us/step - loss: 0.9693 - accuracy: 0.6084 - f1_m: 0.6999 - recall_m: 0.9306 - val_loss: 0.6595 - val_accuracy: 0.7681 - val_f1_m: 0.7990 - val_recall_m: 0.9217\n",
      "Epoch 44/50\n",
      "664/664 [==============================] - 0s 204us/step - loss: 0.9675 - accuracy: 0.6822 - f1_m: 0.7189 - recall_m: 0.7969 - val_loss: 0.6445 - val_accuracy: 0.7651 - val_f1_m: 0.7947 - val_recall_m: 0.9096\n",
      "Epoch 45/50\n",
      "664/664 [==============================] - 0s 105us/step - loss: 0.9098 - accuracy: 0.7093 - f1_m: 0.7318 - recall_m: 0.8000 - val_loss: 0.6315 - val_accuracy: 0.7620 - val_f1_m: 0.7916 - val_recall_m: 0.9036\n",
      "Epoch 46/50\n",
      "664/664 [==============================] - 0s 202us/step - loss: 0.8227 - accuracy: 0.6800 - f1_m: 0.7147 - recall_m: 0.7880 - val_loss: 0.6167 - val_accuracy: 0.7651 - val_f1_m: 0.7937 - val_recall_m: 0.9036\n",
      "Epoch 47/50\n",
      "664/664 [==============================] - 0s 268us/step - loss: 0.8757 - accuracy: 0.7026 - f1_m: 0.7238 - recall_m: 0.7866 - val_loss: 0.6037 - val_accuracy: 0.7651 - val_f1_m: 0.7937 - val_recall_m: 0.9036\n",
      "Epoch 48/50\n",
      "664/664 [==============================] - 0s 135us/step - loss: 0.8861 - accuracy: 0.6619 - f1_m: 0.6791 - recall_m: 0.7355 - val_loss: 0.5988 - val_accuracy: 0.7620 - val_f1_m: 0.7916 - val_recall_m: 0.9036\n",
      "Epoch 49/50\n",
      "664/664 [==============================] - 0s 244us/step - loss: 0.8409 - accuracy: 0.6837 - f1_m: 0.7190 - recall_m: 0.7945 - val_loss: 0.5988 - val_accuracy: 0.7590 - val_f1_m: 0.7938 - val_recall_m: 0.9277\n",
      "Epoch 50/50\n",
      "664/664 [==============================] - 0s 189us/step - loss: 0.8396 - accuracy: 0.6657 - f1_m: 0.6989 - recall_m: 0.7862 - val_loss: 0.5901 - val_accuracy: 0.7590 - val_f1_m: 0.7949 - val_recall_m: 0.9337\n",
      "CNN Error: 24.10%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200,verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5901439979851965, 0.759036123752594, 0.8145730495452881, 0.9427083134651184]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
