{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>927.89</td>\n",
       "      <td>0.04</td>\n",
       "      <td>23.04</td>\n",
       "      <td>40.27</td>\n",
       "      <td>21378.61</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>769.78</td>\n",
       "      <td>0.07</td>\n",
       "      <td>14.86</td>\n",
       "      <td>51.81</td>\n",
       "      <td>11436.73</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>254.75</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.35</td>\n",
       "      <td>27.25</td>\n",
       "      <td>2381.95</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc   v(g)   ev(g)   iv(g)      n       v     l      d      i         e  \\\n",
       "0   1.1    1.4     1.4     1.4    1.3    1.30  1.30   1.30   1.30      1.30   \n",
       "1   1.0    1.0     1.0     1.0    1.0    1.00  1.00   1.00   1.00      1.00   \n",
       "2  83.0   11.0     1.0    11.0  171.0  927.89  0.04  23.04  40.27  21378.61   \n",
       "3  46.0    8.0     6.0     8.0  141.0  769.78  0.07  14.86  51.81  11436.73   \n",
       "4  25.0    3.0     1.0     3.0   58.0  254.75  0.11   9.35  27.25   2381.95   \n",
       "\n",
       "   ...   lOCode   lOComment   lOBlank   locCodeAndComment   uniq_Op  \\\n",
       "0  ...        2           2         2                   2       1.2   \n",
       "1  ...        1           1         1                   1       1.0   \n",
       "2  ...       65          10         6                   0      18.0   \n",
       "3  ...       37           2         5                   0      16.0   \n",
       "4  ...       21           0         2                   0      11.0   \n",
       "\n",
       "    uniq_Opnd   total_Op   total_Opnd   branchCount   defects   \n",
       "0         1.2        1.2          1.2           1.4      False  \n",
       "1         1.0        1.0          1.0           1.0       True  \n",
       "2        25.0      107.0         64.0          21.0       True  \n",
       "3        28.0       89.0         52.0          15.0       True  \n",
       "4        10.0       41.0         17.0           5.0       True  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"dataset/KC1.csv\")\n",
    "data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>t</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2109.00000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "      <td>2109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.372262</td>\n",
       "      <td>2.838028</td>\n",
       "      <td>1.674443</td>\n",
       "      <td>2.546420</td>\n",
       "      <td>49.829445</td>\n",
       "      <td>258.696719</td>\n",
       "      <td>0.319583</td>\n",
       "      <td>6.771242</td>\n",
       "      <td>21.240071</td>\n",
       "      <td>5242.386240</td>\n",
       "      <td>...</td>\n",
       "      <td>291.24504</td>\n",
       "      <td>14.525367</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>1.759602</td>\n",
       "      <td>0.132764</td>\n",
       "      <td>7.631674</td>\n",
       "      <td>9.537316</td>\n",
       "      <td>31.043717</td>\n",
       "      <td>18.786724</td>\n",
       "      <td>4.665908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.754442</td>\n",
       "      <td>3.900763</td>\n",
       "      <td>2.200659</td>\n",
       "      <td>3.375859</td>\n",
       "      <td>83.599874</td>\n",
       "      <td>516.317605</td>\n",
       "      <td>0.317029</td>\n",
       "      <td>7.863646</td>\n",
       "      <td>21.500367</td>\n",
       "      <td>17444.981211</td>\n",
       "      <td>...</td>\n",
       "      <td>969.16516</td>\n",
       "      <td>24.188302</td>\n",
       "      <td>3.085271</td>\n",
       "      <td>3.856850</td>\n",
       "      <td>0.704023</td>\n",
       "      <td>5.730347</td>\n",
       "      <td>12.195727</td>\n",
       "      <td>51.776056</td>\n",
       "      <td>32.074398</td>\n",
       "      <td>7.792206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>5.330000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>57.060000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>14.400000</td>\n",
       "      <td>213.970000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.89000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>265.930000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>9.200000</td>\n",
       "      <td>29.850000</td>\n",
       "      <td>2276.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>126.45000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>288.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>7918.820000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>193.060000</td>\n",
       "      <td>324803.510000</td>\n",
       "      <td>...</td>\n",
       "      <td>18044.64000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>678.000000</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>89.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               loc         v(g)        ev(g)        iv(g)            n  \\\n",
       "count  2109.000000  2109.000000  2109.000000  2109.000000  2109.000000   \n",
       "mean     20.372262     2.838028     1.674443     2.546420    49.829445   \n",
       "std      29.754442     3.900763     2.200659     3.375859    83.599874   \n",
       "min       1.000000     1.000000     1.000000     1.000000     0.000000   \n",
       "25%       3.000000     1.000000     1.000000     1.000000     4.000000   \n",
       "50%       9.000000     1.000000     1.000000     1.000000    16.000000   \n",
       "75%      24.000000     3.000000     1.000000     3.000000    58.000000   \n",
       "max     288.000000    45.000000    26.000000    45.000000  1106.000000   \n",
       "\n",
       "                 v            l            d            i              e  ...  \\\n",
       "count  2109.000000  2109.000000  2109.000000  2109.000000    2109.000000  ...   \n",
       "mean    258.696719     0.319583     6.771242    21.240071    5242.386240  ...   \n",
       "std     516.317605     0.317029     7.863646    21.500367   17444.981211  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000       0.000000  ...   \n",
       "25%       8.000000     0.080000     1.500000     5.330000      12.000000  ...   \n",
       "50%      57.060000     0.200000     3.500000    14.400000     213.970000  ...   \n",
       "75%     265.930000     0.670000     9.200000    29.850000    2276.020000  ...   \n",
       "max    7918.820000     2.000000    53.750000   193.060000  324803.510000  ...   \n",
       "\n",
       "                 t       lOCode    lOComment      lOBlank   locCodeAndComment  \\\n",
       "count   2109.00000  2109.000000  2109.000000  2109.000000         2109.000000   \n",
       "mean     291.24504    14.525367     0.945946     1.759602            0.132764   \n",
       "std      969.16516    24.188302     3.085271     3.856850            0.704023   \n",
       "min        0.00000     0.000000     0.000000     0.000000            0.000000   \n",
       "25%        0.67000     0.000000     0.000000     0.000000            0.000000   \n",
       "50%       11.89000     5.000000     0.000000     0.000000            0.000000   \n",
       "75%      126.45000    17.000000     0.000000     2.000000            0.000000   \n",
       "max    18044.64000   262.000000    44.000000    58.000000           12.000000   \n",
       "\n",
       "           uniq_Op    uniq_Opnd     total_Op   total_Opnd   branchCount  \n",
       "count  2109.000000  2109.000000  2109.000000  2109.000000   2109.000000  \n",
       "mean      7.631674     9.537316    31.043717    18.786724      4.665908  \n",
       "std       5.730347    12.195727    51.776056    32.074398      7.792206  \n",
       "min       0.000000     0.000000     0.000000     0.000000      1.000000  \n",
       "25%       3.000000     1.000000     3.000000     1.000000      1.000000  \n",
       "50%       6.000000     5.000000    10.000000     6.000000      1.000000  \n",
       "75%      11.000000    13.000000    36.000000    22.000000      5.000000  \n",
       "max      37.000000   120.000000   678.000000   428.000000     89.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2109, 22)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1, 1,\n",
       "       1, 1, 1.0, 1.0, 1.0, 1.0, 1.0, 1], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(2102):\n",
    "    if data2[i][21]==True:\n",
    "        data2[i][21]=1\n",
    "    else:\n",
    "        data2[i][21]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.1,   1.4,   1.4, ...,   1.2,   1.2,   1.4],\n",
       "       [  1. ,   1. ,   1. , ...,   1. ,   1. ,   1. ],\n",
       "       [ 83. ,  11. ,   1. , ..., 107. ,  64. ,  21. ],\n",
       "       ...,\n",
       "       [  2. ,   1. ,   1. , ...,   3. ,   1. ,   1. ],\n",
       "       [ 13. ,   1. ,   1. , ...,   9. ,   8. ,   1. ],\n",
       "       [ 11. ,   2. ,   1. , ...,  18. ,   9. ,   3. ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3566, 21), (3566,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3566, 21, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "X_res=X_res.reshape(3566,21,1)\n",
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=1, kernel_size=3 , input_shape=(21,1),activation= 'relu' ))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(21, activation= 'relu' ))\n",
    "    model.add(Dense(num_classes, activation= 'sigmoid' ))\n",
    "# Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy' ,f1_m,recall_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2852 samples, validate on 714 samples\n",
      "Epoch 1/50\n",
      "2852/2852 [==============================] - 1s 382us/step - loss: 858.7698 - accuracy: 0.4851 - f1_m: 0.4376 - recall_m: 0.4034 - val_loss: 728.8046 - val_accuracy: 0.4825 - val_f1_m: 0.4660 - val_recall_m: 0.4602\n",
      "Epoch 2/50\n",
      "2852/2852 [==============================] - 0s 120us/step - loss: 593.8299 - accuracy: 0.4616 - f1_m: 0.4318 - recall_m: 0.4093 - val_loss: 490.7638 - val_accuracy: 0.4678 - val_f1_m: 0.4625 - val_recall_m: 0.4665\n",
      "Epoch 3/50\n",
      "2852/2852 [==============================] - 0s 39us/step - loss: 389.4389 - accuracy: 0.4446 - f1_m: 0.4887 - recall_m: 0.5300 - val_loss: 284.2279 - val_accuracy: 0.4104 - val_f1_m: 0.4397 - val_recall_m: 0.4712\n",
      "Epoch 4/50\n",
      "2852/2852 [==============================] - 0s 64us/step - loss: 233.8605 - accuracy: 0.4912 - f1_m: 0.5920 - recall_m: 0.7444 - val_loss: 177.8896 - val_accuracy: 0.4986 - val_f1_m: 0.6357 - val_recall_m: 0.8796\n",
      "Epoch 5/50\n",
      "2852/2852 [==============================] - 0s 57us/step - loss: 160.5336 - accuracy: 0.4786 - f1_m: 0.6030 - recall_m: 0.7929 - val_loss: 104.5202 - val_accuracy: 0.4342 - val_f1_m: 0.5606 - val_recall_m: 0.7292\n",
      "Epoch 6/50\n",
      "2852/2852 [==============================] - 0s 86us/step - loss: 81.5051 - accuracy: 0.4534 - f1_m: 0.5566 - recall_m: 0.6857 - val_loss: 29.5715 - val_accuracy: 0.4111 - val_f1_m: 0.5017 - val_recall_m: 0.5938\n",
      "Epoch 7/50\n",
      "2852/2852 [==============================] - 0s 34us/step - loss: 23.5145 - accuracy: 0.5047 - f1_m: 0.5079 - recall_m: 0.5138 - val_loss: 11.1607 - val_accuracy: 0.5483 - val_f1_m: 0.5014 - val_recall_m: 0.4459\n",
      "Epoch 8/50\n",
      "2852/2852 [==============================] - 0s 53us/step - loss: 13.1651 - accuracy: 0.5670 - f1_m: 0.5009 - recall_m: 0.4395 - val_loss: 6.5236 - val_accuracy: 0.4986 - val_f1_m: 0.2570 - val_recall_m: 0.1711\n",
      "Epoch 9/50\n",
      "2852/2852 [==============================] - 0s 35us/step - loss: 8.0422 - accuracy: 0.5631 - f1_m: 0.4879 - recall_m: 0.4263 - val_loss: 2.4635 - val_accuracy: 0.6001 - val_f1_m: 0.5352 - val_recall_m: 0.4469\n",
      "Epoch 10/50\n",
      "2852/2852 [==============================] - 0s 81us/step - loss: 5.9233 - accuracy: 0.5636 - f1_m: 0.5125 - recall_m: 0.4589 - val_loss: 2.4184 - val_accuracy: 0.5980 - val_f1_m: 0.5297 - val_recall_m: 0.4400\n",
      "Epoch 11/50\n",
      "2852/2852 [==============================] - 0s 36us/step - loss: 4.5201 - accuracy: 0.5854 - f1_m: 0.5268 - recall_m: 0.4670 - val_loss: 1.6865 - val_accuracy: 0.6015 - val_f1_m: 0.5251 - val_recall_m: 0.4309\n",
      "Epoch 12/50\n",
      "2852/2852 [==============================] - 0s 37us/step - loss: 3.4340 - accuracy: 0.6113 - f1_m: 0.5685 - recall_m: 0.5108 - val_loss: 1.4576 - val_accuracy: 0.6555 - val_f1_m: 0.6149 - val_recall_m: 0.5351\n",
      "Epoch 13/50\n",
      "2852/2852 [==============================] - 0s 38us/step - loss: 3.7855 - accuracy: 0.6083 - f1_m: 0.5646 - recall_m: 0.5062 - val_loss: 1.3870 - val_accuracy: 0.6583 - val_f1_m: 0.6139 - val_recall_m: 0.5304\n",
      "Epoch 14/50\n",
      "2852/2852 [==============================] - 0s 50us/step - loss: 3.6467 - accuracy: 0.6171 - f1_m: 0.5769 - recall_m: 0.5254 - val_loss: 1.0045 - val_accuracy: 0.6576 - val_f1_m: 0.6221 - val_recall_m: 0.5523\n",
      "Epoch 15/50\n",
      "2852/2852 [==============================] - 0s 55us/step - loss: 4.4457 - accuracy: 0.6183 - f1_m: 0.5817 - recall_m: 0.5338 - val_loss: 1.1894 - val_accuracy: 0.6485 - val_f1_m: 0.5726 - val_recall_m: 0.4638\n",
      "Epoch 16/50\n",
      "2852/2852 [==============================] - 0s 48us/step - loss: 3.1080 - accuracy: 0.6366 - f1_m: 0.6011 - recall_m: 0.5533 - val_loss: 1.3298 - val_accuracy: 0.6940 - val_f1_m: 0.6629 - val_recall_m: 0.5889\n",
      "Epoch 17/50\n",
      "2852/2852 [==============================] - 0s 154us/step - loss: 2.5292 - accuracy: 0.6499 - f1_m: 0.6201 - recall_m: 0.5756 - val_loss: 1.1952 - val_accuracy: 0.6064 - val_f1_m: 0.5641 - val_recall_m: 0.5091\n",
      "Epoch 18/50\n",
      "2852/2852 [==============================] - 0s 108us/step - loss: 3.5142 - accuracy: 0.6515 - f1_m: 0.6316 - recall_m: 0.5994 - val_loss: 1.0517 - val_accuracy: 0.7052 - val_f1_m: 0.6770 - val_recall_m: 0.6045\n",
      "Epoch 19/50\n",
      "2852/2852 [==============================] - 0s 153us/step - loss: 3.5501 - accuracy: 0.6636 - f1_m: 0.6352 - recall_m: 0.5899 - val_loss: 0.9243 - val_accuracy: 0.6737 - val_f1_m: 0.6649 - val_recall_m: 0.6452\n",
      "Epoch 20/50\n",
      "2852/2852 [==============================] - 0s 80us/step - loss: 2.6506 - accuracy: 0.6580 - f1_m: 0.6501 - recall_m: 0.6381 - val_loss: 1.0607 - val_accuracy: 0.7164 - val_f1_m: 0.7166 - val_recall_m: 0.7052\n",
      "Epoch 21/50\n",
      "2852/2852 [==============================] - 0s 34us/step - loss: 3.0712 - accuracy: 0.6651 - f1_m: 0.6571 - recall_m: 0.6471 - val_loss: 0.6921 - val_accuracy: 0.7143 - val_f1_m: 0.7041 - val_recall_m: 0.6730\n",
      "Epoch 22/50\n",
      "2852/2852 [==============================] - 0s 30us/step - loss: 2.4467 - accuracy: 0.6709 - f1_m: 0.6568 - recall_m: 0.6347 - val_loss: 1.2615 - val_accuracy: 0.6225 - val_f1_m: 0.6837 - val_recall_m: 0.8155\n",
      "Epoch 23/50\n",
      "2852/2852 [==============================] - 0s 32us/step - loss: 2.9152 - accuracy: 0.6673 - f1_m: 0.6671 - recall_m: 0.6768 - val_loss: 1.2480 - val_accuracy: 0.7178 - val_f1_m: 0.7176 - val_recall_m: 0.7011\n",
      "Epoch 24/50\n",
      "2852/2852 [==============================] - 0s 36us/step - loss: 2.0388 - accuracy: 0.6711 - f1_m: 0.6669 - recall_m: 0.6593 - val_loss: 1.7938 - val_accuracy: 0.7241 - val_f1_m: 0.7305 - val_recall_m: 0.7274\n",
      "Epoch 25/50\n",
      "2852/2852 [==============================] - 0s 33us/step - loss: 2.4952 - accuracy: 0.6676 - f1_m: 0.6747 - recall_m: 0.6964 - val_loss: 0.9702 - val_accuracy: 0.7143 - val_f1_m: 0.7237 - val_recall_m: 0.7383\n",
      "Epoch 26/50\n",
      "2852/2852 [==============================] - 0s 33us/step - loss: 2.2991 - accuracy: 0.6651 - f1_m: 0.6722 - recall_m: 0.6806 - val_loss: 1.4328 - val_accuracy: 0.7276 - val_f1_m: 0.7296 - val_recall_m: 0.7177\n",
      "Epoch 27/50\n",
      "2852/2852 [==============================] - 0s 113us/step - loss: 2.0703 - accuracy: 0.6601 - f1_m: 0.6603 - recall_m: 0.6523 - val_loss: 0.8862 - val_accuracy: 0.7157 - val_f1_m: 0.7087 - val_recall_m: 0.6904\n",
      "Epoch 28/50\n",
      "2852/2852 [==============================] - 0s 119us/step - loss: 1.2895 - accuracy: 0.6560 - f1_m: 0.6610 - recall_m: 0.6736 - val_loss: 0.8334 - val_accuracy: 0.7045 - val_f1_m: 0.7083 - val_recall_m: 0.7130\n",
      "Epoch 29/50\n",
      "2852/2852 [==============================] - 0s 165us/step - loss: 1.3224 - accuracy: 0.6566 - f1_m: 0.6548 - recall_m: 0.6580 - val_loss: 0.8876 - val_accuracy: 0.7122 - val_f1_m: 0.7225 - val_recall_m: 0.7442\n",
      "Epoch 30/50\n",
      "2852/2852 [==============================] - 0s 125us/step - loss: 1.3556 - accuracy: 0.6632 - f1_m: 0.6727 - recall_m: 0.6917 - val_loss: 1.2287 - val_accuracy: 0.6127 - val_f1_m: 0.5252 - val_recall_m: 0.4309\n",
      "Epoch 31/50\n",
      "2852/2852 [==============================] - 0s 52us/step - loss: 1.7121 - accuracy: 0.6453 - f1_m: 0.6414 - recall_m: 0.6548 - val_loss: 0.6451 - val_accuracy: 0.7003 - val_f1_m: 0.6976 - val_recall_m: 0.6932\n",
      "Epoch 32/50\n",
      "2852/2852 [==============================] - 0s 97us/step - loss: 1.8755 - accuracy: 0.6674 - f1_m: 0.6684 - recall_m: 0.6794 - val_loss: 1.1813 - val_accuracy: 0.7150 - val_f1_m: 0.7300 - val_recall_m: 0.7586\n",
      "Epoch 33/50\n",
      "2852/2852 [==============================] - 0s 122us/step - loss: 1.9749 - accuracy: 0.6662 - f1_m: 0.6749 - recall_m: 0.6982 - val_loss: 0.8786 - val_accuracy: 0.7087 - val_f1_m: 0.7199 - val_recall_m: 0.7405\n",
      "Epoch 34/50\n",
      "2852/2852 [==============================] - 0s 154us/step - loss: 1.6325 - accuracy: 0.6643 - f1_m: 0.6694 - recall_m: 0.6995 - val_loss: 1.1394 - val_accuracy: 0.7122 - val_f1_m: 0.7327 - val_recall_m: 0.7824\n",
      "Epoch 35/50\n",
      "2852/2852 [==============================] - 0s 107us/step - loss: 1.5039 - accuracy: 0.6660 - f1_m: 0.6697 - recall_m: 0.6868 - val_loss: 2.1630 - val_accuracy: 0.6029 - val_f1_m: 0.4908 - val_recall_m: 0.3855\n",
      "Epoch 36/50\n",
      "2852/2852 [==============================] - 0s 63us/step - loss: 1.4186 - accuracy: 0.6627 - f1_m: 0.6560 - recall_m: 0.6493 - val_loss: 0.6744 - val_accuracy: 0.7059 - val_f1_m: 0.7103 - val_recall_m: 0.7167\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2852/2852 [==============================] - 0s 47us/step - loss: 1.4040 - accuracy: 0.6825 - f1_m: 0.6816 - recall_m: 0.6911 - val_loss: 1.5253 - val_accuracy: 0.5175 - val_f1_m: 0.5154 - val_recall_m: 0.5197\n",
      "Epoch 38/50\n",
      "2852/2852 [==============================] - 0s 50us/step - loss: 1.7155 - accuracy: 0.6590 - f1_m: 0.6591 - recall_m: 0.6569 - val_loss: 1.1341 - val_accuracy: 0.7185 - val_f1_m: 0.7248 - val_recall_m: 0.7239\n",
      "Epoch 39/50\n",
      "2852/2852 [==============================] - 0s 65us/step - loss: 1.5439 - accuracy: 0.6776 - f1_m: 0.6668 - recall_m: 0.6518 - val_loss: 0.9076 - val_accuracy: 0.6148 - val_f1_m: 0.5263 - val_recall_m: 0.4296\n",
      "Epoch 40/50\n",
      "2852/2852 [==============================] - 0s 110us/step - loss: 1.2817 - accuracy: 0.6667 - f1_m: 0.6590 - recall_m: 0.6567 - val_loss: 1.0046 - val_accuracy: 0.6169 - val_f1_m: 0.6777 - val_recall_m: 0.8093\n",
      "Epoch 41/50\n",
      "2852/2852 [==============================] - ETA: 0s - loss: 1.2271 - accuracy: 0.6656 - f1_m: 0.6692 - recall_m: 0.68 - 0s 70us/step - loss: 1.1040 - accuracy: 0.6701 - f1_m: 0.6701 - recall_m: 0.6735 - val_loss: 0.7247 - val_accuracy: 0.6275 - val_f1_m: 0.5716 - val_recall_m: 0.4959\n",
      "Epoch 42/50\n",
      "2852/2852 [==============================] - 0s 109us/step - loss: 1.0535 - accuracy: 0.6699 - f1_m: 0.6762 - recall_m: 0.6838 - val_loss: 1.1776 - val_accuracy: 0.6239 - val_f1_m: 0.5060 - val_recall_m: 0.3837\n",
      "Epoch 43/50\n",
      "2852/2852 [==============================] - 0s 104us/step - loss: 1.7784 - accuracy: 0.6653 - f1_m: 0.6668 - recall_m: 0.6590 - val_loss: 1.6990 - val_accuracy: 0.7192 - val_f1_m: 0.7142 - val_recall_m: 0.6861\n",
      "Epoch 44/50\n",
      "2852/2852 [==============================] - 0s 123us/step - loss: 1.7184 - accuracy: 0.6757 - f1_m: 0.6738 - recall_m: 0.6698 - val_loss: 0.9587 - val_accuracy: 0.7157 - val_f1_m: 0.7213 - val_recall_m: 0.7220\n",
      "Epoch 45/50\n",
      "2852/2852 [==============================] - 0s 107us/step - loss: 1.3136 - accuracy: 0.6792 - f1_m: 0.6741 - recall_m: 0.6735 - val_loss: 0.7187 - val_accuracy: 0.7059 - val_f1_m: 0.7033 - val_recall_m: 0.6908\n",
      "Epoch 46/50\n",
      "2852/2852 [==============================] - 0s 63us/step - loss: 1.2276 - accuracy: 0.6744 - f1_m: 0.6591 - recall_m: 0.6359 - val_loss: 0.9118 - val_accuracy: 0.7122 - val_f1_m: 0.7117 - val_recall_m: 0.6961\n",
      "Epoch 47/50\n",
      "2852/2852 [==============================] - 0s 76us/step - loss: 1.3342 - accuracy: 0.6795 - f1_m: 0.6700 - recall_m: 0.6533 - val_loss: 0.6237 - val_accuracy: 0.6961 - val_f1_m: 0.6881 - val_recall_m: 0.6670\n",
      "Epoch 48/50\n",
      "2852/2852 [==============================] - 0s 101us/step - loss: 1.4477 - accuracy: 0.6785 - f1_m: 0.6664 - recall_m: 0.6467 - val_loss: 0.7414 - val_accuracy: 0.7143 - val_f1_m: 0.7227 - val_recall_m: 0.7358\n",
      "Epoch 49/50\n",
      "2852/2852 [==============================] - 0s 128us/step - loss: 1.2979 - accuracy: 0.6665 - f1_m: 0.6679 - recall_m: 0.6712 - val_loss: 1.1122 - val_accuracy: 0.7192 - val_f1_m: 0.7357 - val_recall_m: 0.7696\n",
      "Epoch 50/50\n",
      "2852/2852 [==============================] - 0s 138us/step - loss: 1.2311 - accuracy: 0.6727 - f1_m: 0.6715 - recall_m: 0.6757 - val_loss: 0.9402 - val_accuracy: 0.7136 - val_f1_m: 0.7289 - val_recall_m: 0.7602\n",
      "CNN Error: 28.64%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200,verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.940170990485771, 0.7135854363441467, 0.7218640446662903, 0.7529891729354858]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
