{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>309.13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>9.50</td>\n",
       "      <td>32.54</td>\n",
       "      <td>2936.77</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>215.49</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16.00</td>\n",
       "      <td>13.47</td>\n",
       "      <td>3447.89</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>346.13</td>\n",
       "      <td>0.06</td>\n",
       "      <td>17.33</td>\n",
       "      <td>19.97</td>\n",
       "      <td>5999.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc   v(g)   ev(g)   iv(g)    n        v    l       d      i        e  \\\n",
       "0   1.1    1.4     1.4     1.4   1.3    1.30  1.30   1.30   1.30     1.30   \n",
       "1   1.0    1.0     1.0     1.0   1.0    1.00  1.00   1.00   1.00     1.00   \n",
       "2  24.0    5.0     1.0     3.0  63.0  309.13  0.11   9.50  32.54  2936.77   \n",
       "3  20.0    4.0     4.0     2.0  47.0  215.49  0.06  16.00  13.47  3447.89   \n",
       "4  24.0    6.0     6.0     2.0  72.0  346.13  0.06  17.33  19.97  5999.58   \n",
       "\n",
       "   ...   lOCode   lOComment   lOBlank   locCodeAndComment   uniq_Op  \\\n",
       "0  ...        2           2         2                   2       1.2   \n",
       "1  ...        1           1         1                   1       1.0   \n",
       "2  ...        1           0         6                   0      15.0   \n",
       "3  ...        0           0         3                   0      16.0   \n",
       "4  ...        0           0         3                   0      16.0   \n",
       "\n",
       "    uniq_Opnd   total_Op   total_Opnd   branchCount   defects  \n",
       "0         1.2        1.2          1.2           1.4     False  \n",
       "1         1.0        1.0          1.0           1.0      True  \n",
       "2        15.0       44.0         19.0           9.0     False  \n",
       "3         8.0       31.0         16.0           7.0     False  \n",
       "4        12.0       46.0         26.0          11.0     False  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"dataset/CM1.csv\")\n",
    "data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>t</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>locCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>4.980000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.644779</td>\n",
       "      <td>5.382329</td>\n",
       "      <td>2.490763</td>\n",
       "      <td>3.528916</td>\n",
       "      <td>143.956426</td>\n",
       "      <td>900.175823</td>\n",
       "      <td>0.146325</td>\n",
       "      <td>15.829378</td>\n",
       "      <td>38.455361</td>\n",
       "      <td>3.488493e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1938.056124</td>\n",
       "      <td>3.787149</td>\n",
       "      <td>12.283133</td>\n",
       "      <td>11.534137</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>15.199197</td>\n",
       "      <td>25.452209</td>\n",
       "      <td>88.389960</td>\n",
       "      <td>55.570683</td>\n",
       "      <td>9.348193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.753572</td>\n",
       "      <td>8.347359</td>\n",
       "      <td>3.658847</td>\n",
       "      <td>5.464398</td>\n",
       "      <td>221.049888</td>\n",
       "      <td>1690.814334</td>\n",
       "      <td>0.159337</td>\n",
       "      <td>15.330960</td>\n",
       "      <td>36.996297</td>\n",
       "      <td>1.341647e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>7453.591519</td>\n",
       "      <td>8.508658</td>\n",
       "      <td>25.828605</td>\n",
       "      <td>19.981476</td>\n",
       "      <td>0.100120</td>\n",
       "      <td>9.617815</td>\n",
       "      <td>33.925816</td>\n",
       "      <td>134.917513</td>\n",
       "      <td>86.969527</td>\n",
       "      <td>15.072219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>102.190000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>5.630000</td>\n",
       "      <td>16.210000</td>\n",
       "      <td>6.061700e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>33.672500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>329.820000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>11.640000</td>\n",
       "      <td>27.400000</td>\n",
       "      <td>3.677620e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>204.310000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>151.750000</td>\n",
       "      <td>861.460000</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>21.142500</td>\n",
       "      <td>46.900000</td>\n",
       "      <td>1.663334e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>924.075000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>94.750000</td>\n",
       "      <td>59.750000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>423.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>2075.000000</td>\n",
       "      <td>17124.280000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>125.770000</td>\n",
       "      <td>293.680000</td>\n",
       "      <td>2.153691e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>119649.480000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>314.000000</td>\n",
       "      <td>1261.000000</td>\n",
       "      <td>814.000000</td>\n",
       "      <td>162.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              loc        v(g)       ev(g)       iv(g)           n   \\\n",
       "count  498.000000  498.000000  498.000000  498.000000   498.000000   \n",
       "mean    29.644779    5.382329    2.490763    3.528916   143.956426   \n",
       "std     42.753572    8.347359    3.658847    5.464398   221.049888   \n",
       "min      1.000000    1.000000    1.000000    1.000000     1.000000   \n",
       "25%      8.000000    1.000000    1.000000    1.000000    25.000000   \n",
       "50%     17.000000    3.000000    1.000000    2.000000    67.500000   \n",
       "75%     31.000000    6.000000    1.000000    4.000000   151.750000   \n",
       "max    423.000000   96.000000   30.000000   63.000000  2075.000000   \n",
       "\n",
       "                  v          l            d           i             e  ...  \\\n",
       "count    498.000000  498.000000  498.000000  498.000000  4.980000e+02  ...   \n",
       "mean     900.175823    0.146325   15.829378   38.455361  3.488493e+04  ...   \n",
       "std     1690.814334    0.159337   15.330960   36.996297  1.341647e+05  ...   \n",
       "min        0.000000    0.000000    0.000000    0.000000  0.000000e+00  ...   \n",
       "25%      102.190000    0.050000    5.630000   16.210000  6.061700e+02  ...   \n",
       "50%      329.820000    0.090000   11.640000   27.400000  3.677620e+03  ...   \n",
       "75%      861.460000    0.177500   21.142500   46.900000  1.663334e+04  ...   \n",
       "max    17124.280000    1.300000  125.770000  293.680000  2.153691e+06  ...   \n",
       "\n",
       "                   t      lOCode   lOComment     lOBlank   locCodeAndComment  \\\n",
       "count     498.000000  498.000000  498.000000  498.000000          498.000000   \n",
       "mean     1938.056124    3.787149   12.283133   11.534137            0.006024   \n",
       "std      7453.591519    8.508658   25.828605   19.981476            0.100120   \n",
       "min         0.000000    0.000000    0.000000    0.000000            0.000000   \n",
       "25%        33.672500    0.000000    0.000000    1.000000            0.000000   \n",
       "50%       204.310000    1.000000    4.000000    5.000000            0.000000   \n",
       "75%       924.075000    4.000000   14.000000   13.000000            0.000000   \n",
       "max    119649.480000   80.000000  339.000000  164.000000            2.000000   \n",
       "\n",
       "          uniq_Op   uniq_Opnd     total_Op   total_Opnd   branchCount  \n",
       "count  498.000000  498.000000   498.000000   498.000000    498.000000  \n",
       "mean    15.199197   25.452209    88.389960    55.570683      9.348193  \n",
       "std      9.617815   33.925816   134.917513    86.969527     15.072219  \n",
       "min      1.000000    0.000000     1.000000     0.000000      1.000000  \n",
       "25%      9.000000    7.000000    15.000000    10.000000      1.000000  \n",
       "50%     14.000000   15.000000    42.000000    26.000000      5.000000  \n",
       "75%     20.000000   30.000000    94.750000    59.750000     11.000000  \n",
       "max     72.000000  314.000000  1261.000000   814.000000    162.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498, 22)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1, 1,\n",
       "       1, 1, 1.0, 1.0, 1.0, 1.0, 1.0, 1], dtype=object)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(498):\n",
    "    if data2[i][21]==True:\n",
    "        data2[i][21]=1\n",
    "    else:\n",
    "        data2[i][21]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.1,   1.4,   1.4, ...,   1.2,   1.2,   1.4],\n",
       "       [  1. ,   1. ,   1. , ...,   1. ,   1. ,   1. ],\n",
       "       [ 24. ,   5. ,   1. , ...,  44. ,  19. ,   9. ],\n",
       "       ...,\n",
       "       [ 82. ,  11. ,   3. , ..., 285. , 190. ,  21. ],\n",
       "       [ 10. ,   2. ,   1. , ...,  19. ,  13. ,   3. ],\n",
       "       [ 28. ,   6. ,   5. , ...,  67. ,  37. ,  11. ]])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((898, 21), (898,))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(898, 21, 1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "X_res=X_res.reshape(898,21,1)\n",
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=1, kernel_size=3 , input_shape=(21,1),activation= 'relu' ))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(21, activation= 'relu' ))\n",
    "    model.add(Dense(num_classes, activation= 'sigmoid' ))\n",
    "# Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy' ,f1_m,recall_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 718 samples, validate on 180 samples\n",
      "Epoch 1/50\n",
      "718/718 [==============================] - 1s 2ms/step - loss: 5364.6702 - accuracy: 0.5174 - f1_m: 0.3605 - recall_m: 0.2773 - val_loss: 3148.2154 - val_accuracy: 0.5667 - val_f1_m: 0.5660 - val_recall_m: 0.5517\n",
      "Epoch 2/50\n",
      "718/718 [==============================] - 0s 191us/step - loss: 4002.8215 - accuracy: 0.5125 - f1_m: 0.3731 - recall_m: 0.2910 - val_loss: 2011.6012 - val_accuracy: 0.5944 - val_f1_m: 0.5295 - val_recall_m: 0.4483\n",
      "Epoch 3/50\n",
      "718/718 [==============================] - 0s 346us/step - loss: 2595.9268 - accuracy: 0.5251 - f1_m: 0.4068 - recall_m: 0.3289 - val_loss: 1020.8065 - val_accuracy: 0.5278 - val_f1_m: 0.5512 - val_recall_m: 0.5667\n",
      "Epoch 4/50\n",
      "718/718 [==============================] - 0s 223us/step - loss: 1480.5689 - accuracy: 0.4721 - f1_m: 0.4268 - recall_m: 0.3982 - val_loss: 81.3599 - val_accuracy: 0.5250 - val_f1_m: 0.5982 - val_recall_m: 0.7083\n",
      "Epoch 5/50\n",
      "718/718 [==============================] - 0s 252us/step - loss: 887.5127 - accuracy: 0.5021 - f1_m: 0.5579 - recall_m: 0.6363 - val_loss: 150.1080 - val_accuracy: 0.5111 - val_f1_m: 0.6685 - val_recall_m: 0.9850\n",
      "Epoch 6/50\n",
      "718/718 [==============================] - 0s 362us/step - loss: 896.3128 - accuracy: 0.5104 - f1_m: 0.5797 - recall_m: 0.6745 - val_loss: 150.5772 - val_accuracy: 0.5139 - val_f1_m: 0.6697 - val_recall_m: 0.9850\n",
      "Epoch 7/50\n",
      "718/718 [==============================] - 0s 283us/step - loss: 540.4029 - accuracy: 0.5125 - f1_m: 0.6000 - recall_m: 0.7367 - val_loss: 118.6597 - val_accuracy: 0.5083 - val_f1_m: 0.6592 - val_recall_m: 0.9500\n",
      "Epoch 8/50\n",
      "718/718 [==============================] - 0s 204us/step - loss: 830.5184 - accuracy: 0.5021 - f1_m: 0.5961 - recall_m: 0.7388 - val_loss: 116.9172 - val_accuracy: 0.5139 - val_f1_m: 0.6685 - val_recall_m: 0.9800\n",
      "Epoch 9/50\n",
      "718/718 [==============================] - 0s 269us/step - loss: 518.7379 - accuracy: 0.5118 - f1_m: 0.5957 - recall_m: 0.7258 - val_loss: 94.2900 - val_accuracy: 0.5000 - val_f1_m: 0.6667 - val_recall_m: 1.0000\n",
      "Epoch 10/50\n",
      "718/718 [==============================] - 0s 121us/step - loss: 556.7373 - accuracy: 0.5021 - f1_m: 0.5876 - recall_m: 0.7065 - val_loss: 120.4260 - val_accuracy: 0.4972 - val_f1_m: 0.6644 - val_recall_m: 0.9950\n",
      "Epoch 11/50\n",
      "718/718 [==============================] - 0s 123us/step - loss: 1107.2236 - accuracy: 0.4812 - f1_m: 0.5554 - recall_m: 0.6439 - val_loss: 61.5800 - val_accuracy: 0.5111 - val_f1_m: 0.6478 - val_recall_m: 0.8967\n",
      "Epoch 12/50\n",
      "718/718 [==============================] - 0s 139us/step - loss: 756.2163 - accuracy: 0.5056 - f1_m: 0.5874 - recall_m: 0.7190 - val_loss: 36.9215 - val_accuracy: 0.5083 - val_f1_m: 0.6358 - val_recall_m: 0.8583\n",
      "Epoch 13/50\n",
      "718/718 [==============================] - 0s 130us/step - loss: 397.4583 - accuracy: 0.5056 - f1_m: 0.5911 - recall_m: 0.7116 - val_loss: 40.2324 - val_accuracy: 0.5111 - val_f1_m: 0.6478 - val_recall_m: 0.8967\n",
      "Epoch 14/50\n",
      "718/718 [==============================] - 0s 143us/step - loss: 563.8804 - accuracy: 0.5084 - f1_m: 0.5737 - recall_m: 0.6723 - val_loss: 124.8835 - val_accuracy: 0.4972 - val_f1_m: 0.6644 - val_recall_m: 0.9950\n",
      "Epoch 15/50\n",
      "718/718 [==============================] - 0s 155us/step - loss: 359.2273 - accuracy: 0.4979 - f1_m: 0.5757 - recall_m: 0.6834 - val_loss: 64.9669 - val_accuracy: 0.5056 - val_f1_m: 0.5447 - val_recall_m: 0.5983\n",
      "Epoch 16/50\n",
      "718/718 [==============================] - 0s 129us/step - loss: 447.4423 - accuracy: 0.5007 - f1_m: 0.5556 - recall_m: 0.6372 - val_loss: 53.5494 - val_accuracy: 0.5056 - val_f1_m: 0.6569 - val_recall_m: 0.9450\n",
      "Epoch 17/50\n",
      "718/718 [==============================] - 0s 130us/step - loss: 332.5453 - accuracy: 0.5111 - f1_m: 0.5868 - recall_m: 0.6938 - val_loss: 42.3595 - val_accuracy: 0.5056 - val_f1_m: 0.6569 - val_recall_m: 0.9450\n",
      "Epoch 18/50\n",
      "718/718 [==============================] - 0s 189us/step - loss: 269.3069 - accuracy: 0.4749 - f1_m: 0.5414 - recall_m: 0.6221 - val_loss: 31.4488 - val_accuracy: 0.5028 - val_f1_m: 0.6388 - val_recall_m: 0.8783\n",
      "Epoch 19/50\n",
      "718/718 [==============================] - 0s 135us/step - loss: 313.3086 - accuracy: 0.5070 - f1_m: 0.5659 - recall_m: 0.6547 - val_loss: 70.3490 - val_accuracy: 0.4806 - val_f1_m: 0.6442 - val_recall_m: 0.9433\n",
      "Epoch 20/50\n",
      "718/718 [==============================] - 0s 178us/step - loss: 303.3610 - accuracy: 0.5007 - f1_m: 0.5660 - recall_m: 0.6544 - val_loss: 45.6827 - val_accuracy: 0.4806 - val_f1_m: 0.6478 - val_recall_m: 0.9583\n",
      "Epoch 21/50\n",
      "718/718 [==============================] - 0s 185us/step - loss: 182.9865 - accuracy: 0.5223 - f1_m: 0.5688 - recall_m: 0.6327 - val_loss: 24.3021 - val_accuracy: 0.4972 - val_f1_m: 0.6352 - val_recall_m: 0.8750\n",
      "Epoch 22/50\n",
      "718/718 [==============================] - 0s 143us/step - loss: 210.7648 - accuracy: 0.4951 - f1_m: 0.5560 - recall_m: 0.6413 - val_loss: 35.6066 - val_accuracy: 0.4917 - val_f1_m: 0.6584 - val_recall_m: 0.9817\n",
      "Epoch 23/50\n",
      "718/718 [==============================] - 0s 132us/step - loss: 164.1344 - accuracy: 0.5049 - f1_m: 0.5651 - recall_m: 0.6517 - val_loss: 102.4021 - val_accuracy: 0.4833 - val_f1_m: 0.6454 - val_recall_m: 0.9433\n",
      "Epoch 24/50\n",
      "718/718 [==============================] - 0s 139us/step - loss: 194.1041 - accuracy: 0.5084 - f1_m: 0.5606 - recall_m: 0.6351 - val_loss: 22.5006 - val_accuracy: 0.5139 - val_f1_m: 0.6299 - val_recall_m: 0.8250\n",
      "Epoch 25/50\n",
      "718/718 [==============================] - 0s 170us/step - loss: 163.5726 - accuracy: 0.5244 - f1_m: 0.5784 - recall_m: 0.6557 - val_loss: 16.6969 - val_accuracy: 0.4972 - val_f1_m: 0.6268 - val_recall_m: 0.8450\n",
      "Epoch 26/50\n",
      "718/718 [==============================] - 0s 401us/step - loss: 282.5786 - accuracy: 0.4833 - f1_m: 0.5463 - recall_m: 0.6244 - val_loss: 88.5879 - val_accuracy: 0.4444 - val_f1_m: 0.4333 - val_recall_m: 0.4333\n",
      "Epoch 27/50\n",
      "718/718 [==============================] - 0s 157us/step - loss: 304.7301 - accuracy: 0.5460 - f1_m: 0.5611 - recall_m: 0.5865 - val_loss: 58.8780 - val_accuracy: 0.4694 - val_f1_m: 0.6166 - val_recall_m: 0.8567\n",
      "Epoch 28/50\n",
      "718/718 [==============================] - 0s 368us/step - loss: 197.7245 - accuracy: 0.4993 - f1_m: 0.5493 - recall_m: 0.6151 - val_loss: 22.1372 - val_accuracy: 0.4889 - val_f1_m: 0.6316 - val_recall_m: 0.8733\n",
      "Epoch 29/50\n",
      "718/718 [==============================] - 0s 159us/step - loss: 204.3533 - accuracy: 0.5063 - f1_m: 0.5639 - recall_m: 0.6388 - val_loss: 17.4421 - val_accuracy: 0.5111 - val_f1_m: 0.6613 - val_recall_m: 0.9567\n",
      "Epoch 30/50\n",
      "718/718 [==============================] - 0s 420us/step - loss: 103.8127 - accuracy: 0.4882 - f1_m: 0.5600 - recall_m: 0.6519 - val_loss: 30.8341 - val_accuracy: 0.4778 - val_f1_m: 0.6185 - val_recall_m: 0.8517\n",
      "Epoch 31/50\n",
      "718/718 [==============================] - 0s 456us/step - loss: 239.7768 - accuracy: 0.4930 - f1_m: 0.5082 - recall_m: 0.5391 - val_loss: 78.5307 - val_accuracy: 0.4833 - val_f1_m: 0.6516 - val_recall_m: 0.9667\n",
      "Epoch 32/50\n",
      "718/718 [==============================] - 0s 274us/step - loss: 247.5506 - accuracy: 0.5007 - f1_m: 0.5420 - recall_m: 0.6040 - val_loss: 27.9535 - val_accuracy: 0.5000 - val_f1_m: 0.4922 - val_recall_m: 0.4933\n",
      "Epoch 33/50\n",
      "718/718 [==============================] - 0s 343us/step - loss: 126.2167 - accuracy: 0.5042 - f1_m: 0.5299 - recall_m: 0.5634 - val_loss: 61.0179 - val_accuracy: 0.4972 - val_f1_m: 0.6644 - val_recall_m: 0.9950\n",
      "Epoch 34/50\n",
      "718/718 [==============================] - 0s 275us/step - loss: 190.8754 - accuracy: 0.4937 - f1_m: 0.5022 - recall_m: 0.5193 - val_loss: 24.1264 - val_accuracy: 0.4583 - val_f1_m: 0.4582 - val_recall_m: 0.4650\n",
      "Epoch 35/50\n",
      "718/718 [==============================] - 0s 436us/step - loss: 135.4829 - accuracy: 0.4979 - f1_m: 0.5461 - recall_m: 0.6120 - val_loss: 52.8307 - val_accuracy: 0.4583 - val_f1_m: 0.4578 - val_recall_m: 0.4650\n",
      "Epoch 36/50\n",
      "718/718 [==============================] - 0s 552us/step - loss: 132.8887 - accuracy: 0.5125 - f1_m: 0.5508 - recall_m: 0.6061 - val_loss: 25.8198 - val_accuracy: 0.4889 - val_f1_m: 0.5068 - val_recall_m: 0.5283\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718/718 [==============================] - 0s 338us/step - loss: 81.2668 - accuracy: 0.5390 - f1_m: 0.5892 - recall_m: 0.6652 - val_loss: 19.0295 - val_accuracy: 0.5472 - val_f1_m: 0.6405 - val_recall_m: 0.8050\n",
      "Epoch 38/50\n",
      "718/718 [==============================] - 0s 386us/step - loss: 109.1360 - accuracy: 0.5153 - f1_m: 0.5782 - recall_m: 0.6671 - val_loss: 17.2487 - val_accuracy: 0.5500 - val_f1_m: 0.6430 - val_recall_m: 0.8100\n",
      "Epoch 39/50\n",
      "718/718 [==============================] - 0s 511us/step - loss: 93.2585 - accuracy: 0.5258 - f1_m: 0.5578 - recall_m: 0.6016 - val_loss: 31.6819 - val_accuracy: 0.4889 - val_f1_m: 0.6436 - val_recall_m: 0.9183\n",
      "Epoch 40/50\n",
      "718/718 [==============================] - 0s 355us/step - loss: 83.4099 - accuracy: 0.5174 - f1_m: 0.5714 - recall_m: 0.6467 - val_loss: 16.3693 - val_accuracy: 0.4500 - val_f1_m: 0.4523 - val_recall_m: 0.4600\n",
      "Epoch 41/50\n",
      "718/718 [==============================] - 0s 416us/step - loss: 172.7497 - accuracy: 0.4993 - f1_m: 0.5316 - recall_m: 0.5644 - val_loss: 11.1772 - val_accuracy: 0.4694 - val_f1_m: 0.4738 - val_recall_m: 0.4833\n",
      "Epoch 42/50\n",
      "718/718 [==============================] - 0s 318us/step - loss: 99.7362 - accuracy: 0.5118 - f1_m: 0.5325 - recall_m: 0.5778 - val_loss: 13.8516 - val_accuracy: 0.4833 - val_f1_m: 0.4730 - val_recall_m: 0.4700\n",
      "Epoch 43/50\n",
      "718/718 [==============================] - 0s 426us/step - loss: 75.9451 - accuracy: 0.5209 - f1_m: 0.5620 - recall_m: 0.6170 - val_loss: 8.1680 - val_accuracy: 0.4806 - val_f1_m: 0.4641 - val_recall_m: 0.4533\n",
      "Epoch 44/50\n",
      "718/718 [==============================] - 0s 297us/step - loss: 100.6413 - accuracy: 0.5091 - f1_m: 0.5170 - recall_m: 0.5356 - val_loss: 23.0778 - val_accuracy: 0.4972 - val_f1_m: 0.4092 - val_recall_m: 0.3533\n",
      "Epoch 45/50\n",
      "718/718 [==============================] - 0s 605us/step - loss: 95.1695 - accuracy: 0.5188 - f1_m: 0.5310 - recall_m: 0.5607 - val_loss: 23.7435 - val_accuracy: 0.5222 - val_f1_m: 0.6344 - val_recall_m: 0.8333\n",
      "Epoch 46/50\n",
      "718/718 [==============================] - 0s 447us/step - loss: 154.7869 - accuracy: 0.5146 - f1_m: 0.5394 - recall_m: 0.5671 - val_loss: 51.9887 - val_accuracy: 0.4944 - val_f1_m: 0.5919 - val_recall_m: 0.7400\n",
      "Epoch 47/50\n",
      "718/718 [==============================] - 0s 446us/step - loss: 85.8973 - accuracy: 0.5348 - f1_m: 0.5453 - recall_m: 0.5567 - val_loss: 29.4934 - val_accuracy: 0.5000 - val_f1_m: 0.4889 - val_recall_m: 0.4833\n",
      "Epoch 48/50\n",
      "718/718 [==============================] - 0s 258us/step - loss: 70.8015 - accuracy: 0.5404 - f1_m: 0.5470 - recall_m: 0.5633 - val_loss: 17.0488 - val_accuracy: 0.4972 - val_f1_m: 0.4921 - val_recall_m: 0.4933\n",
      "Epoch 49/50\n",
      "718/718 [==============================] - 0s 266us/step - loss: 70.1861 - accuracy: 0.5160 - f1_m: 0.5379 - recall_m: 0.5695 - val_loss: 21.1706 - val_accuracy: 0.4972 - val_f1_m: 0.5511 - val_recall_m: 0.6283\n",
      "Epoch 50/50\n",
      "718/718 [==============================] - 0s 329us/step - loss: 66.0644 - accuracy: 0.5446 - f1_m: 0.5422 - recall_m: 0.5588 - val_loss: 10.3119 - val_accuracy: 0.5167 - val_f1_m: 0.5433 - val_recall_m: 0.5850\n",
      "CNN Error: 48.33%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=50,verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.31195035510593, 0.5166666507720947, 0.5489484667778015, 0.5916666388511658]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
