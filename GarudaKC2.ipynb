{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>lOCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>problems</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>415.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>8411.31</td>\n",
       "      <td>0.01</td>\n",
       "      <td>103.53</td>\n",
       "      <td>81.24</td>\n",
       "      <td>870848.58</td>\n",
       "      <td>...</td>\n",
       "      <td>359</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>47.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>3732.82</td>\n",
       "      <td>0.03</td>\n",
       "      <td>39.82</td>\n",
       "      <td>93.74</td>\n",
       "      <td>148644.06</td>\n",
       "      <td>...</td>\n",
       "      <td>174</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3123.96</td>\n",
       "      <td>0.03</td>\n",
       "      <td>29.48</td>\n",
       "      <td>105.96</td>\n",
       "      <td>92103.07</td>\n",
       "      <td>...</td>\n",
       "      <td>142</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     loc   v(g)   ev(g)   iv(g)       n        v     l       d       i  \\\n",
       "0    1.1    1.4     1.4     1.4     1.3     1.30  1.30    1.30    1.30   \n",
       "1    1.0    1.0     1.0     1.0     1.0     1.00  1.00    1.00    1.00   \n",
       "2  415.0   59.0    50.0    51.0  1159.0  8411.31  0.01  103.53   81.24   \n",
       "3  230.0   33.0    10.0    16.0   575.0  3732.82  0.03   39.82   93.74   \n",
       "4  175.0   26.0    12.0    13.0   500.0  3123.96  0.03   29.48  105.96   \n",
       "\n",
       "           e  ...   lOCode   lOComment   lOBlank   lOCodeAndComment   uniq_Op  \\\n",
       "0       1.30  ...        2           2         2                  2       1.2   \n",
       "1       1.00  ...        1           1         1                  1       1.0   \n",
       "2  870848.58  ...      359          35         9                 10      47.0   \n",
       "3  148644.06  ...      174          15        34                  5      23.0   \n",
       "4   92103.07  ...      142           7        19                  4      18.0   \n",
       "\n",
       "    uniq_Opnd   total_Op   total_Opnd   branchCount   problems   \n",
       "0         1.2        1.2          1.2           1.4          no  \n",
       "1         1.0        1.0          1.0           1.0         yes  \n",
       "2       106.0      692.0        467.0         106.0         yes  \n",
       "3        67.0      343.0        232.0          65.0         yes  \n",
       "4        58.0      310.0        190.0          51.0         yes  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"dataset/KC2.csv\")\n",
    "data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>t</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>lOComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>lOCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>5.220000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "      <td>522.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>36.894828</td>\n",
       "      <td>4.893487</td>\n",
       "      <td>2.447126</td>\n",
       "      <td>3.650192</td>\n",
       "      <td>94.630843</td>\n",
       "      <td>555.472644</td>\n",
       "      <td>0.274464</td>\n",
       "      <td>9.735287</td>\n",
       "      <td>28.320441</td>\n",
       "      <td>1.854299e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1094.811456</td>\n",
       "      <td>27.772031</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.339080</td>\n",
       "      <td>0.281609</td>\n",
       "      <td>9.197701</td>\n",
       "      <td>14.465900</td>\n",
       "      <td>57.611494</td>\n",
       "      <td>37.023372</td>\n",
       "      <td>8.765134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.944048</td>\n",
       "      <td>10.976772</td>\n",
       "      <td>6.665003</td>\n",
       "      <td>8.054860</td>\n",
       "      <td>233.230165</td>\n",
       "      <td>1817.468320</td>\n",
       "      <td>0.275609</td>\n",
       "      <td>11.088640</td>\n",
       "      <td>32.225597</td>\n",
       "      <td>1.132712e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>7556.521581</td>\n",
       "      <td>64.431485</td>\n",
       "      <td>5.582052</td>\n",
       "      <td>9.214753</td>\n",
       "      <td>1.038236</td>\n",
       "      <td>6.360180</td>\n",
       "      <td>22.086661</td>\n",
       "      <td>142.990741</td>\n",
       "      <td>90.398620</td>\n",
       "      <td>21.942779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>11.610000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>7.740000</td>\n",
       "      <td>1.741000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>109.205000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.560000</td>\n",
       "      <td>6.135900e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>34.090000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>104.750000</td>\n",
       "      <td>543.787500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>14.610000</td>\n",
       "      <td>38.365000</td>\n",
       "      <td>7.624085e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>423.562500</td>\n",
       "      <td>33.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1275.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>3982.000000</td>\n",
       "      <td>33814.560000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>103.530000</td>\n",
       "      <td>415.060000</td>\n",
       "      <td>2.147484e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>153047.010000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>2469.000000</td>\n",
       "      <td>1513.000000</td>\n",
       "      <td>361.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               loc        v(g)       ev(g)       iv(g)            n  \\\n",
       "count   522.000000  522.000000  522.000000  522.000000   522.000000   \n",
       "mean     36.894828    4.893487    2.447126    3.650192    94.630843   \n",
       "std      77.944048   10.976772    6.665003    8.054860   233.230165   \n",
       "min       1.000000    1.000000    1.000000    1.000000     1.000000   \n",
       "25%       4.000000    1.000000    1.000000    1.000000     5.000000   \n",
       "50%      13.000000    2.000000    1.000000    2.000000    27.000000   \n",
       "75%      45.000000    5.000000    1.000000    4.000000   104.750000   \n",
       "max    1275.000000  180.000000  125.000000  143.000000  3982.000000   \n",
       "\n",
       "                  v           l           d           i             e  ...  \\\n",
       "count    522.000000  522.000000  522.000000  522.000000  5.220000e+02  ...   \n",
       "mean     555.472644    0.274464    9.735287   28.320441  1.854299e+04  ...   \n",
       "std     1817.468320    0.275609   11.088640   32.225597  1.132712e+05  ...   \n",
       "min        0.000000    0.000000    0.000000    0.000000  0.000000e+00  ...   \n",
       "25%       11.610000    0.060000    1.500000    7.740000  1.741000e+01  ...   \n",
       "50%      109.205000    0.140000    6.000000   20.560000  6.135900e+02  ...   \n",
       "75%      543.787500    0.500000   14.610000   38.365000  7.624085e+03  ...   \n",
       "max    33814.560000    2.000000  103.530000  415.060000  2.147484e+06  ...   \n",
       "\n",
       "                   t       lOCode   lOComment     lOBlank   lOCodeAndComment  \\\n",
       "count     522.000000   522.000000  522.000000  522.000000         522.000000   \n",
       "mean     1094.811456    27.772031    2.000000    4.339080           0.281609   \n",
       "std      7556.521581    64.431485    5.582052    9.214753           1.038236   \n",
       "min         0.000000     0.000000    0.000000    0.000000           0.000000   \n",
       "25%         0.970000     2.000000    0.000000    0.000000           0.000000   \n",
       "50%        34.090000     8.000000    0.000000    1.000000           0.000000   \n",
       "75%       423.562500    33.750000    2.000000    5.000000           0.000000   \n",
       "max    153047.010000  1107.000000   44.000000  121.000000          11.000000   \n",
       "\n",
       "          uniq_Op   uniq_Opnd     total_Op   total_Opnd   branchCount  \n",
       "count  522.000000  522.000000   522.000000   522.000000    522.000000  \n",
       "mean     9.197701   14.465900    57.611494    37.023372      8.765134  \n",
       "std      6.360180   22.086661   142.990741    90.398620     21.942779  \n",
       "min      1.000000    0.000000     1.000000     0.000000      1.000000  \n",
       "25%      3.000000    2.000000     4.000000     2.000000      1.000000  \n",
       "50%      8.000000    7.000000    16.500000    11.000000      3.000000  \n",
       "75%     14.000000   20.000000    64.000000    41.000000      9.000000  \n",
       "max     47.000000  325.000000  2469.000000  1513.000000    361.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(522, 22)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1, 1,\n",
       "       1, 1, 1.0, 1.0, 1.0, 1.0, 1.0, 1], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(522):\n",
    "    if data2[i][21]=='yes':\n",
    "        data2[i][21]=1\n",
    "    else:\n",
    "        data2[i][21]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.1,   1.4,   1.4, ...,   1.2,   1.2,   1.4],\n",
       "       [  1. ,   1. ,   1. , ...,   1. ,   1. ,   1. ],\n",
       "       [415. ,  59. ,  50. , ..., 692. , 467. , 106. ],\n",
       "       ...,\n",
       "       [  4. ,   1. ,   1. , ...,   3. ,   1. ,   1. ],\n",
       "       [  4. ,   1. ,   1. , ...,   3. ,   2. ,   1. ],\n",
       "       [  3. ,   1. ,   1. , ...,   1. ,   0. ,   1. ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous-multioutput'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-57494be3f501>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#os =  RandomOverSampler()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mX_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \"\"\"\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    167\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    168\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous-multioutput'"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 21, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "X_res=X_res.reshape(830,21,1)\n",
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=1, kernel_size=3 , input_shape=(21,1),activation= 'relu' ))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(21, activation= 'relu' ))\n",
    "    model.add(Dense(num_classes, activation= 'sigmoid' ))\n",
    "# Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy' ,f1_m,recall_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 664 samples, validate on 166 samples\n",
      "Epoch 1/50\n",
      "664/664 [==============================] - 1s 2ms/step - loss: 3271.2497 - accuracy: 0.4985 - f1_m: 0.0695 - recall_m: 0.0380 - val_loss: 2433.2585 - val_accuracy: 0.4940 - val_f1_m: 0.0233 - val_recall_m: 0.0120\n",
      "Epoch 2/50\n",
      "664/664 [==============================] - 0s 198us/step - loss: 3686.2909 - accuracy: 0.4910 - f1_m: 0.0510 - recall_m: 0.0277 - val_loss: 2279.6453 - val_accuracy: 0.4940 - val_f1_m: 0.0233 - val_recall_m: 0.0120\n",
      "Epoch 3/50\n",
      "664/664 [==============================] - 0s 178us/step - loss: 3292.4190 - accuracy: 0.5023 - f1_m: 0.0710 - recall_m: 0.0380 - val_loss: 2128.4141 - val_accuracy: 0.4940 - val_f1_m: 0.0233 - val_recall_m: 0.0120\n",
      "Epoch 4/50\n",
      "664/664 [==============================] - 0s 175us/step - loss: 2648.8212 - accuracy: 0.4962 - f1_m: 0.0544 - recall_m: 0.0292 - val_loss: 1986.1979 - val_accuracy: 0.4970 - val_f1_m: 0.0347 - val_recall_m: 0.0181\n",
      "Epoch 5/50\n",
      "664/664 [==============================] - 0s 126us/step - loss: 2597.2656 - accuracy: 0.4985 - f1_m: 0.0659 - recall_m: 0.0353 - val_loss: 1848.5339 - val_accuracy: 0.5000 - val_f1_m: 0.0460 - val_recall_m: 0.0241\n",
      "Epoch 6/50\n",
      "664/664 [==============================] - 0s 126us/step - loss: 2647.0143 - accuracy: 0.5023 - f1_m: 0.0749 - recall_m: 0.0406 - val_loss: 1711.6449 - val_accuracy: 0.5000 - val_f1_m: 0.0460 - val_recall_m: 0.0241\n",
      "Epoch 7/50\n",
      "664/664 [==============================] - 0s 215us/step - loss: 2123.6328 - accuracy: 0.5053 - f1_m: 0.0728 - recall_m: 0.0391 - val_loss: 1573.9508 - val_accuracy: 0.5000 - val_f1_m: 0.0460 - val_recall_m: 0.0241\n",
      "Epoch 8/50\n",
      "664/664 [==============================] - 0s 133us/step - loss: 1991.9222 - accuracy: 0.5030 - f1_m: 0.0680 - recall_m: 0.0366 - val_loss: 1437.5941 - val_accuracy: 0.4940 - val_f1_m: 0.0455 - val_recall_m: 0.0241\n",
      "Epoch 9/50\n",
      "664/664 [==============================] - 0s 272us/step - loss: 1938.7806 - accuracy: 0.4917 - f1_m: 0.0906 - recall_m: 0.0522 - val_loss: 1305.1265 - val_accuracy: 0.5000 - val_f1_m: 0.0674 - val_recall_m: 0.0361\n",
      "Epoch 10/50\n",
      "664/664 [==============================] - 0s 123us/step - loss: 1739.4592 - accuracy: 0.4947 - f1_m: 0.0956 - recall_m: 0.0531 - val_loss: 1170.3082 - val_accuracy: 0.5000 - val_f1_m: 0.0674 - val_recall_m: 0.0361\n",
      "Epoch 11/50\n",
      "664/664 [==============================] - 0s 154us/step - loss: 1565.4322 - accuracy: 0.5008 - f1_m: 0.1112 - recall_m: 0.0634 - val_loss: 1035.9951 - val_accuracy: 0.5000 - val_f1_m: 0.0674 - val_recall_m: 0.0361\n",
      "Epoch 12/50\n",
      "664/664 [==============================] - 0s 275us/step - loss: 1329.4439 - accuracy: 0.4932 - f1_m: 0.1071 - recall_m: 0.0617 - val_loss: 902.4271 - val_accuracy: 0.5000 - val_f1_m: 0.0674 - val_recall_m: 0.0361\n",
      "Epoch 13/50\n",
      "664/664 [==============================] - 0s 258us/step - loss: 1202.4264 - accuracy: 0.4872 - f1_m: 0.1124 - recall_m: 0.0659 - val_loss: 773.4613 - val_accuracy: 0.5000 - val_f1_m: 0.0674 - val_recall_m: 0.0361\n",
      "Epoch 14/50\n",
      "664/664 [==============================] - 0s 139us/step - loss: 966.0368 - accuracy: 0.4970 - f1_m: 0.1872 - recall_m: 0.1197 - val_loss: 640.8005 - val_accuracy: 0.5000 - val_f1_m: 0.0674 - val_recall_m: 0.0361\n",
      "Epoch 15/50\n",
      "664/664 [==============================] - 0s 131us/step - loss: 644.2903 - accuracy: 0.5256 - f1_m: 0.2484 - recall_m: 0.1580 - val_loss: 515.7717 - val_accuracy: 0.5000 - val_f1_m: 0.0674 - val_recall_m: 0.0361\n",
      "Epoch 16/50\n",
      "664/664 [==============================] - 0s 131us/step - loss: 566.4590 - accuracy: 0.4880 - f1_m: 0.2176 - recall_m: 0.1437 - val_loss: 395.6516 - val_accuracy: 0.4970 - val_f1_m: 0.0670 - val_recall_m: 0.0361\n",
      "Epoch 17/50\n",
      "664/664 [==============================] - 0s 153us/step - loss: 335.8648 - accuracy: 0.5045 - f1_m: 0.2057 - recall_m: 0.1308 - val_loss: 281.1661 - val_accuracy: 0.4940 - val_f1_m: 0.0667 - val_recall_m: 0.0361\n",
      "Epoch 18/50\n",
      "664/664 [==============================] - 0s 143us/step - loss: 243.9692 - accuracy: 0.4970 - f1_m: 0.2275 - recall_m: 0.1503 - val_loss: 163.5899 - val_accuracy: 0.5000 - val_f1_m: 0.0978 - val_recall_m: 0.0542\n",
      "Epoch 19/50\n",
      "664/664 [==============================] - 0s 232us/step - loss: 112.6332 - accuracy: 0.5663 - f1_m: 0.4617 - recall_m: 0.3761 - val_loss: 153.6245 - val_accuracy: 0.5633 - val_f1_m: 0.4765 - val_recall_m: 0.3976\n",
      "Epoch 20/50\n",
      "664/664 [==============================] - 0s 177us/step - loss: 101.2481 - accuracy: 0.5904 - f1_m: 0.5553 - recall_m: 0.5138 - val_loss: 152.5570 - val_accuracy: 0.5271 - val_f1_m: 0.4749 - val_recall_m: 0.4277\n",
      "Epoch 21/50\n",
      "664/664 [==============================] - 0s 188us/step - loss: 116.0955 - accuracy: 0.5505 - f1_m: 0.5546 - recall_m: 0.5425 - val_loss: 148.2400 - val_accuracy: 0.5060 - val_f1_m: 0.4744 - val_recall_m: 0.4458\n",
      "Epoch 22/50\n",
      "664/664 [==============================] - 0s 252us/step - loss: 111.3153 - accuracy: 0.5670 - f1_m: 0.5642 - recall_m: 0.5522 - val_loss: 142.0319 - val_accuracy: 0.5090 - val_f1_m: 0.4858 - val_recall_m: 0.4639\n",
      "Epoch 23/50\n",
      "664/664 [==============================] - 0s 200us/step - loss: 98.5207 - accuracy: 0.5648 - f1_m: 0.5593 - recall_m: 0.5552 - val_loss: 134.8080 - val_accuracy: 0.5030 - val_f1_m: 0.4828 - val_recall_m: 0.4639\n",
      "Epoch 24/50\n",
      "664/664 [==============================] - 0s 182us/step - loss: 98.0494 - accuracy: 0.5776 - f1_m: 0.5802 - recall_m: 0.5720 - val_loss: 126.3648 - val_accuracy: 0.5030 - val_f1_m: 0.4828 - val_recall_m: 0.4639\n",
      "Epoch 25/50\n",
      "664/664 [==============================] - 0s 166us/step - loss: 92.3963 - accuracy: 0.5685 - f1_m: 0.5814 - recall_m: 0.5769 - val_loss: 116.5706 - val_accuracy: 0.5030 - val_f1_m: 0.4828 - val_recall_m: 0.4639\n",
      "Epoch 26/50\n",
      "664/664 [==============================] - 0s 177us/step - loss: 89.2733 - accuracy: 0.5572 - f1_m: 0.5596 - recall_m: 0.5583 - val_loss: 106.1918 - val_accuracy: 0.5090 - val_f1_m: 0.4890 - val_recall_m: 0.4699\n",
      "Epoch 27/50\n",
      "664/664 [==============================] - 0s 171us/step - loss: 77.3264 - accuracy: 0.5723 - f1_m: 0.5816 - recall_m: 0.5900 - val_loss: 95.9316 - val_accuracy: 0.5120 - val_f1_m: 0.4906 - val_recall_m: 0.4699\n",
      "Epoch 28/50\n",
      "664/664 [==============================] - 0s 146us/step - loss: 56.5790 - accuracy: 0.5723 - f1_m: 0.5776 - recall_m: 0.5736 - val_loss: 85.6909 - val_accuracy: 0.5241 - val_f1_m: 0.4968 - val_recall_m: 0.4699\n",
      "Epoch 29/50\n",
      "664/664 [==============================] - 0s 168us/step - loss: 53.6330 - accuracy: 0.5949 - f1_m: 0.5895 - recall_m: 0.5795 - val_loss: 75.4925 - val_accuracy: 0.5301 - val_f1_m: 0.5000 - val_recall_m: 0.4699\n",
      "Epoch 30/50\n",
      "664/664 [==============================] - 0s 57us/step - loss: 49.4350 - accuracy: 0.6032 - f1_m: 0.6101 - recall_m: 0.6081 - val_loss: 65.0310 - val_accuracy: 0.5572 - val_f1_m: 0.5051 - val_recall_m: 0.4518\n",
      "Epoch 31/50\n",
      "664/664 [==============================] - 0s 28us/step - loss: 37.7395 - accuracy: 0.6107 - f1_m: 0.6228 - recall_m: 0.6391 - val_loss: 54.8202 - val_accuracy: 0.5602 - val_f1_m: 0.5068 - val_recall_m: 0.4518\n",
      "Epoch 32/50\n",
      "664/664 [==============================] - 0s 39us/step - loss: 34.5901 - accuracy: 0.5889 - f1_m: 0.6034 - recall_m: 0.6323 - val_loss: 44.1959 - val_accuracy: 0.5693 - val_f1_m: 0.5119 - val_recall_m: 0.4518\n",
      "Epoch 33/50\n",
      "664/664 [==============================] - 0s 43us/step - loss: 29.4527 - accuracy: 0.6107 - f1_m: 0.6227 - recall_m: 0.6455 - val_loss: 33.3995 - val_accuracy: 0.5663 - val_f1_m: 0.5034 - val_recall_m: 0.4398\n",
      "Epoch 34/50\n",
      "664/664 [==============================] - 0s 28us/step - loss: 27.7214 - accuracy: 0.5828 - f1_m: 0.6058 - recall_m: 0.6427 - val_loss: 30.2754 - val_accuracy: 0.5753 - val_f1_m: 0.5087 - val_recall_m: 0.4398\n",
      "Epoch 35/50\n",
      "664/664 [==============================] - 0s 41us/step - loss: 32.1768 - accuracy: 0.5926 - f1_m: 0.5873 - recall_m: 0.5928 - val_loss: 38.6304 - val_accuracy: 0.5783 - val_f1_m: 0.5070 - val_recall_m: 0.4337\n",
      "Epoch 36/50\n",
      "664/664 [==============================] - 0s 60us/step - loss: 29.1024 - accuracy: 0.6092 - f1_m: 0.5913 - recall_m: 0.5744 - val_loss: 42.6465 - val_accuracy: 0.5934 - val_f1_m: 0.5126 - val_recall_m: 0.4277\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "664/664 [==============================] - 0s 30us/step - loss: 25.7259 - accuracy: 0.6175 - f1_m: 0.6022 - recall_m: 0.5841 - val_loss: 42.8058 - val_accuracy: 0.6024 - val_f1_m: 0.5182 - val_recall_m: 0.4277\n",
      "Epoch 38/50\n",
      "664/664 [==============================] - 0s 34us/step - loss: 32.6154 - accuracy: 0.6242 - f1_m: 0.6018 - recall_m: 0.5689 - val_loss: 40.4272 - val_accuracy: 0.6054 - val_f1_m: 0.5166 - val_recall_m: 0.4217\n",
      "Epoch 39/50\n",
      "664/664 [==============================] - 0s 30us/step - loss: 25.3777 - accuracy: 0.6303 - f1_m: 0.6167 - recall_m: 0.5781 - val_loss: 36.5347 - val_accuracy: 0.6175 - val_f1_m: 0.5208 - val_recall_m: 0.4157\n",
      "Epoch 40/50\n",
      "664/664 [==============================] - 0s 98us/step - loss: 27.0398 - accuracy: 0.6099 - f1_m: 0.5943 - recall_m: 0.5789 - val_loss: 31.3749 - val_accuracy: 0.6235 - val_f1_m: 0.5283 - val_recall_m: 0.4217\n",
      "Epoch 41/50\n",
      "664/664 [==============================] - 0s 55us/step - loss: 21.6996 - accuracy: 0.6220 - f1_m: 0.6074 - recall_m: 0.5881 - val_loss: 25.4251 - val_accuracy: 0.6566 - val_f1_m: 0.5809 - val_recall_m: 0.4759\n",
      "Epoch 42/50\n",
      "664/664 [==============================] - 0s 45us/step - loss: 13.7110 - accuracy: 0.6416 - f1_m: 0.6190 - recall_m: 0.5870 - val_loss: 18.9383 - val_accuracy: 0.6476 - val_f1_m: 0.5651 - val_recall_m: 0.4578\n",
      "Epoch 43/50\n",
      "664/664 [==============================] - 0s 28us/step - loss: 18.9405 - accuracy: 0.6265 - f1_m: 0.6094 - recall_m: 0.5763 - val_loss: 17.8386 - val_accuracy: 0.6446 - val_f1_m: 0.5496 - val_recall_m: 0.4337\n",
      "Epoch 44/50\n",
      "664/664 [==============================] - 0s 26us/step - loss: 12.8798 - accuracy: 0.6431 - f1_m: 0.6110 - recall_m: 0.5623 - val_loss: 18.5420 - val_accuracy: 0.6325 - val_f1_m: 0.5159 - val_recall_m: 0.3916\n",
      "Epoch 45/50\n",
      "664/664 [==============================] - 0s 27us/step - loss: 13.4775 - accuracy: 0.6483 - f1_m: 0.6099 - recall_m: 0.5344 - val_loss: 16.7879 - val_accuracy: 0.6446 - val_f1_m: 0.5124 - val_recall_m: 0.3735\n",
      "Epoch 46/50\n",
      "664/664 [==============================] - 0s 27us/step - loss: 10.9815 - accuracy: 0.6619 - f1_m: 0.6195 - recall_m: 0.5703 - val_loss: 15.2606 - val_accuracy: 0.6325 - val_f1_m: 0.4831 - val_recall_m: 0.3434\n",
      "Epoch 47/50\n",
      "664/664 [==============================] - 0s 31us/step - loss: 10.4690 - accuracy: 0.6491 - f1_m: 0.6098 - recall_m: 0.5508 - val_loss: 15.1531 - val_accuracy: 0.6114 - val_f1_m: 0.4317 - val_recall_m: 0.2952\n",
      "Epoch 48/50\n",
      "664/664 [==============================] - 0s 27us/step - loss: 10.2561 - accuracy: 0.6498 - f1_m: 0.6157 - recall_m: 0.5633 - val_loss: 14.3371 - val_accuracy: 0.5994 - val_f1_m: 0.3927 - val_recall_m: 0.2590\n",
      "Epoch 49/50\n",
      "664/664 [==============================] - 0s 27us/step - loss: 10.6182 - accuracy: 0.6175 - f1_m: 0.5842 - recall_m: 0.5434 - val_loss: 14.2420 - val_accuracy: 0.6024 - val_f1_m: 0.3945 - val_recall_m: 0.2590\n",
      "Epoch 50/50\n",
      "664/664 [==============================] - 0s 28us/step - loss: 9.9515 - accuracy: 0.6355 - f1_m: 0.5880 - recall_m: 0.5364 - val_loss: 13.6798 - val_accuracy: 0.5994 - val_f1_m: 0.3927 - val_recall_m: 0.2590\n",
      "CNN Error: 40.06%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200,verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.679805479853986, 0.599397599697113, 0.3702419698238373, 0.2465277761220932]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
