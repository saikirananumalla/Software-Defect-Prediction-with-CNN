{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>10OComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>lOCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "      <th>defects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>318</td>\n",
       "      <td>2089.21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>27.68</td>\n",
       "      <td>75.47</td>\n",
       "      <td>57833.24</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>44</td>\n",
       "      <td>11</td>\n",
       "      <td>31</td>\n",
       "      <td>29</td>\n",
       "      <td>66</td>\n",
       "      <td>192</td>\n",
       "      <td>126</td>\n",
       "      <td>17</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>381</td>\n",
       "      <td>2547.56</td>\n",
       "      <td>0.04</td>\n",
       "      <td>28.37</td>\n",
       "      <td>89.79</td>\n",
       "      <td>72282.68</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>41</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>28</td>\n",
       "      <td>75</td>\n",
       "      <td>229</td>\n",
       "      <td>152</td>\n",
       "      <td>38</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>505</td>\n",
       "      <td>106</td>\n",
       "      <td>41</td>\n",
       "      <td>82</td>\n",
       "      <td>2339</td>\n",
       "      <td>20696.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>75.93</td>\n",
       "      <td>272.58</td>\n",
       "      <td>1571506.88</td>\n",
       "      <td>...</td>\n",
       "      <td>457</td>\n",
       "      <td>71</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "      <td>64</td>\n",
       "      <td>397</td>\n",
       "      <td>1397</td>\n",
       "      <td>942</td>\n",
       "      <td>178</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>619</td>\n",
       "      <td>4282.78</td>\n",
       "      <td>0.02</td>\n",
       "      <td>52.91</td>\n",
       "      <td>80.95</td>\n",
       "      <td>226588.75</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>86</td>\n",
       "      <td>359</td>\n",
       "      <td>260</td>\n",
       "      <td>40</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>294</td>\n",
       "      <td>1917.93</td>\n",
       "      <td>0.03</td>\n",
       "      <td>28.77</td>\n",
       "      <td>66.66</td>\n",
       "      <td>55178.46</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>71</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "      <td>29</td>\n",
       "      <td>63</td>\n",
       "      <td>169</td>\n",
       "      <td>125</td>\n",
       "      <td>21</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    loc   v(g)   ev(g)   iv(g)     n         v     l      d       i  \\\n",
       "0    91      9       3       2   318   2089.21  0.04  27.68   75.47   \n",
       "1   109     21       5      18   381   2547.56  0.04  28.37   89.79   \n",
       "2   505    106      41      82  2339  20696.93  0.01  75.93  272.58   \n",
       "3   107     25       7      14   619   4282.78  0.02  52.91   80.95   \n",
       "4    74     11       1       8   294   1917.93  0.03  28.77   66.66   \n",
       "\n",
       "            e  ...   lOCode   10OComment   lOBlank   lOCodeAndComment  \\\n",
       "0    57833.24  ...       80           44        11                 31   \n",
       "1    72282.68  ...       97           41        12                 24   \n",
       "2  1571506.88  ...      457           71        48                 49   \n",
       "3   226588.75  ...      103           32         4                 39   \n",
       "4    55178.46  ...       60           71        14                 49   \n",
       "\n",
       "    uniq_Op   uniq_Opnd   total_Op   total_Opnd   branchCount   defects  \n",
       "0        29          66        192          126            17     true   \n",
       "1        28          75        229          152            38     true   \n",
       "2        64         397       1397          942           178     true   \n",
       "3        35          86        359          260            40     true   \n",
       "4        29          63        169          125            21     true   \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"dataset/PC1.csv\")\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loc</th>\n",
       "      <th>v(g)</th>\n",
       "      <th>ev(g)</th>\n",
       "      <th>iv(g)</th>\n",
       "      <th>n</th>\n",
       "      <th>v</th>\n",
       "      <th>l</th>\n",
       "      <th>d</th>\n",
       "      <th>i</th>\n",
       "      <th>e</th>\n",
       "      <th>...</th>\n",
       "      <th>t</th>\n",
       "      <th>lOCode</th>\n",
       "      <th>10OComment</th>\n",
       "      <th>lOBlank</th>\n",
       "      <th>lOCodeAndComment</th>\n",
       "      <th>uniq_Op</th>\n",
       "      <th>uniq_Opnd</th>\n",
       "      <th>total_Op</th>\n",
       "      <th>total_Opnd</th>\n",
       "      <th>branchCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1.107000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.416441</td>\n",
       "      <td>5.518519</td>\n",
       "      <td>2.769648</td>\n",
       "      <td>3.325203</td>\n",
       "      <td>117.603433</td>\n",
       "      <td>700.973297</td>\n",
       "      <td>0.127570</td>\n",
       "      <td>15.422005</td>\n",
       "      <td>32.961843</td>\n",
       "      <td>2.887495e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>1604.163948</td>\n",
       "      <td>22.472448</td>\n",
       "      <td>4.701897</td>\n",
       "      <td>0.943993</td>\n",
       "      <td>6.755194</td>\n",
       "      <td>13.329720</td>\n",
       "      <td>20.928636</td>\n",
       "      <td>66.611563</td>\n",
       "      <td>50.991870</td>\n",
       "      <td>9.591689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.303118</td>\n",
       "      <td>8.965191</td>\n",
       "      <td>5.572331</td>\n",
       "      <td>6.407142</td>\n",
       "      <td>197.453254</td>\n",
       "      <td>1510.617359</td>\n",
       "      <td>0.140379</td>\n",
       "      <td>16.341026</td>\n",
       "      <td>35.393870</td>\n",
       "      <td>1.707934e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>9488.523309</td>\n",
       "      <td>33.593166</td>\n",
       "      <td>10.527052</td>\n",
       "      <td>3.348170</td>\n",
       "      <td>12.310284</td>\n",
       "      <td>8.173119</td>\n",
       "      <td>29.065483</td>\n",
       "      <td>111.769537</td>\n",
       "      <td>86.360681</td>\n",
       "      <td>16.551783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>97.670000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>5.710000</td>\n",
       "      <td>14.090000</td>\n",
       "      <td>5.627650e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>31.265000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>276.600000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>11.670000</td>\n",
       "      <td>23.580000</td>\n",
       "      <td>3.192000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>177.330000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>678.135000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>20.510000</td>\n",
       "      <td>41.150000</td>\n",
       "      <td>1.240090e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>688.935000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>602.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>2785.000000</td>\n",
       "      <td>25942.690000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>270.660000</td>\n",
       "      <td>598.330000</td>\n",
       "      <td>4.279633e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>237757.400000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>538.000000</td>\n",
       "      <td>1641.000000</td>\n",
       "      <td>1144.000000</td>\n",
       "      <td>236.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               loc         v(g)        ev(g)        iv(g)            n  \\\n",
       "count  1107.000000  1107.000000  1107.000000  1107.000000  1107.000000   \n",
       "mean     23.416441     5.518519     2.769648     3.325203   117.603433   \n",
       "std      35.303118     8.965191     5.572331     6.407142   197.453254   \n",
       "min       0.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "25%       7.000000     1.000000     1.000000     1.000000    25.000000   \n",
       "50%      13.000000     3.000000     1.000000     2.000000    58.000000   \n",
       "75%      26.000000     6.000000     3.000000     3.000000   126.500000   \n",
       "max     602.000000   136.000000   123.000000   123.000000  2785.000000   \n",
       "\n",
       "                  v            l            d            i             e  ...  \\\n",
       "count   1107.000000  1107.000000  1107.000000  1107.000000  1.107000e+03  ...   \n",
       "mean     700.973297     0.127570    15.422005    32.961843  2.887495e+04  ...   \n",
       "std     1510.617359     0.140379    16.341026    35.393870  1.707934e+05  ...   \n",
       "min        0.000000     0.000000     0.000000     0.000000  0.000000e+00  ...   \n",
       "25%       97.670000     0.045000     5.710000    14.090000  5.627650e+02  ...   \n",
       "50%      276.600000     0.080000    11.670000    23.580000  3.192000e+03  ...   \n",
       "75%      678.135000     0.160000    20.510000    41.150000  1.240090e+04  ...   \n",
       "max    25942.690000     2.000000   270.660000   598.330000  4.279633e+06  ...   \n",
       "\n",
       "                   t       lOCode   10OComment      lOBlank  \\\n",
       "count    1107.000000  1107.000000  1107.000000  1107.000000   \n",
       "mean     1604.163948    22.472448     4.701897     0.943993   \n",
       "std      9488.523309    33.593166    10.527052     3.348170   \n",
       "min         0.000000     0.000000     0.000000     0.000000   \n",
       "25%        31.265000     7.000000     0.000000     0.000000   \n",
       "50%       177.330000    13.000000     0.000000     0.000000   \n",
       "75%       688.935000    24.000000     5.000000     1.000000   \n",
       "max    237757.400000   600.000000   159.000000    48.000000   \n",
       "\n",
       "        lOCodeAndComment      uniq_Op    uniq_Opnd     total_Op   total_Opnd  \\\n",
       "count        1107.000000  1107.000000  1107.000000  1107.000000  1107.000000   \n",
       "mean            6.755194    13.329720    20.928636    66.611563    50.991870   \n",
       "std            12.310284     8.173119    29.065483   111.769537    86.360681   \n",
       "min             0.000000     1.000000     0.000000     1.000000     0.000000   \n",
       "25%             1.000000     8.000000     6.000000    15.000000    10.000000   \n",
       "50%             3.000000    12.000000    12.000000    33.000000    24.000000   \n",
       "75%             8.000000    17.000000    25.000000    72.000000    56.000000   \n",
       "max           225.000000    99.000000   538.000000  1641.000000  1144.000000   \n",
       "\n",
       "        branchCount  \n",
       "count   1107.000000  \n",
       "mean       9.591689  \n",
       "std       16.551783  \n",
       "min        1.000000  \n",
       "25%        1.000000  \n",
       "50%        5.000000  \n",
       "75%       11.000000  \n",
       "max      236.000000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1107, 22)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([109, 21, 5, 18, 381, 2547.56, 0.04, 28.37, 89.79, 72282.68, 0.85,\n",
       "       4015.7, 97, 41, 12, 24, 28, 75, 229, 152, 38, 1], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(1107):\n",
    "    if data2[i][21]=='true ':\n",
    "        data2[i][21]=1\n",
    "    if data2[i][21]==\"false \":\n",
    "        data2[i][21]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  91.,    9.,    3., ...,  192.,  126.,   17.],\n",
       "       [ 109.,   21.,    5., ...,  229.,  152.,   38.],\n",
       "       [ 505.,  106.,   41., ..., 1397.,  942.,  178.],\n",
       "       ...,\n",
       "       [   5.,    3.,    3., ...,   11.,    6.,    5.],\n",
       "       [  18.,    8.,    5., ...,   61.,   50.,   15.],\n",
       "       [  26.,   18.,   13., ...,  119.,  109.,   35.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2062, 21), (2062,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2062, 21, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "X_res=X_res.reshape(2062,21,1)\n",
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=1, kernel_size=3 , input_shape=(21,1),activation= 'relu' ))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(21, activation= 'relu' ))\n",
    "    model.add(Dense(num_classes, activation= 'sigmoid' ))\n",
    "# Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy' ,f1_m,recall_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1649 samples, validate on 413 samples\n",
      "Epoch 1/50\n",
      "1649/1649 [==============================] - 1s 738us/step - loss: 0.6931 - accuracy: 0.5039 - f1_m: 0.4489 - recall_m: 0.4489 - val_loss: 0.6932 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 2/50\n",
      "1649/1649 [==============================] - 0s 133us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5084 - recall_m: 0.5084 - val_loss: 0.6933 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 3/50\n",
      "1649/1649 [==============================] - 0s 117us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5135 - recall_m: 0.5135 - val_loss: 0.6933 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 4/50\n",
      "1649/1649 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.4981 - recall_m: 0.4981 - val_loss: 0.6934 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 5/50\n",
      "1649/1649 [==============================] - 0s 46us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5135 - recall_m: 0.5135 - val_loss: 0.6934 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 6/50\n",
      "1649/1649 [==============================] - 0s 63us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5084 - recall_m: 0.5084 - val_loss: 0.6935 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 7/50\n",
      "1649/1649 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5016 - recall_m: 0.5016 - val_loss: 0.6935 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 8/50\n",
      "1649/1649 [==============================] - 0s 66us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5067 - recall_m: 0.5067 - val_loss: 0.6935 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 9/50\n",
      "1649/1649 [==============================] - 0s 71us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5118 - recall_m: 0.5118 - val_loss: 0.6935 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 10/50\n",
      "1649/1649 [==============================] - 0s 191us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5050 - recall_m: 0.5050 - val_loss: 0.6936 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 11/50\n",
      "1649/1649 [==============================] - 0s 80us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.4981 - recall_m: 0.4981 - val_loss: 0.6936 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 12/50\n",
      "1649/1649 [==============================] - 0s 97us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5050 - recall_m: 0.5050 - val_loss: 0.6936 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 13/50\n",
      "1649/1649 [==============================] - 0s 101us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5170 - recall_m: 0.5170 - val_loss: 0.6936 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 14/50\n",
      "1649/1649 [==============================] - 0s 71us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5101 - recall_m: 0.5101 - val_loss: 0.6936 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 15/50\n",
      "1649/1649 [==============================] - 0s 64us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5135 - recall_m: 0.5135 - val_loss: 0.6937 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 16/50\n",
      "1649/1649 [==============================] - 0s 60us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5101 - recall_m: 0.5101 - val_loss: 0.6937 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 17/50\n",
      "1649/1649 [==============================] - 0s 113us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5050 - recall_m: 0.5050 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 18/50\n",
      "1649/1649 [==============================] - 0s 52us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5084 - recall_m: 0.5084 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 19/50\n",
      "1649/1649 [==============================] - 0s 36us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5084 - recall_m: 0.5084 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 20/50\n",
      "1649/1649 [==============================] - 0s 83us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5152 - recall_m: 0.5152 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 21/50\n",
      "1649/1649 [==============================] - 0s 70us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5067 - recall_m: 0.5067 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 22/50\n",
      "1649/1649 [==============================] - 0s 53us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5050 - recall_m: 0.5050 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 23/50\n",
      "1649/1649 [==============================] - 0s 97us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5101 - recall_m: 0.5101 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 24/50\n",
      "1649/1649 [==============================] - 0s 53us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5016 - recall_m: 0.5016 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 25/50\n",
      "1649/1649 [==============================] - 0s 42us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5187 - recall_m: 0.5187 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 26/50\n",
      "1649/1649 [==============================] - 0s 129us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.4964 - recall_m: 0.4964 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 27/50\n",
      "1649/1649 [==============================] - 0s 117us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5016 - recall_m: 0.5016 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 28/50\n",
      "1649/1649 [==============================] - 0s 89us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5084 - recall_m: 0.5084 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 29/50\n",
      "1649/1649 [==============================] - 0s 39us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5067 - recall_m: 0.5067 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 30/50\n",
      "1649/1649 [==============================] - 0s 78us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5016 - recall_m: 0.5016 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 31/50\n",
      "1649/1649 [==============================] - 0s 130us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.4998 - recall_m: 0.4998 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 32/50\n",
      "1649/1649 [==============================] - 0s 66us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5101 - recall_m: 0.5101 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 33/50\n",
      "1649/1649 [==============================] - 0s 64us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5067 - recall_m: 0.5067 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 34/50\n",
      "1649/1649 [==============================] - 0s 66us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.4981 - recall_m: 0.4981 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 35/50\n",
      "1649/1649 [==============================] - 0s 70us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5050 - recall_m: 0.5050 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 36/50\n",
      "1649/1649 [==============================] - 0s 77us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5152 - recall_m: 0.5152 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 37/50\n",
      "1649/1649 [==============================] - 0s 79us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5016 - recall_m: 0.5016 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "1649/1649 [==============================] - 0s 62us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5033 - recall_m: 0.5033 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 39/50\n",
      "1649/1649 [==============================] - 0s 50us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5067 - recall_m: 0.5067 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 40/50\n",
      "1649/1649 [==============================] - 0s 79us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5084 - recall_m: 0.5084 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 41/50\n",
      "1649/1649 [==============================] - 0s 97us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5084 - recall_m: 0.5084 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 42/50\n",
      "1649/1649 [==============================] - 0s 94us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5101 - recall_m: 0.5101 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 43/50\n",
      "1649/1649 [==============================] - 0s 39us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5067 - recall_m: 0.5067 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 44/50\n",
      "1649/1649 [==============================] - 0s 55us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.4947 - recall_m: 0.4947 - val_loss: 0.6939 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 45/50\n",
      "1649/1649 [==============================] - 0s 66us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5016 - recall_m: 0.5016 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 46/50\n",
      "1649/1649 [==============================] - 0s 52us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.4964 - recall_m: 0.4964 - val_loss: 0.6938 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 47/50\n",
      "1649/1649 [==============================] - 0s 52us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5033 - recall_m: 0.5033 - val_loss: 0.6937 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 48/50\n",
      "1649/1649 [==============================] - 0s 75us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5152 - recall_m: 0.5152 - val_loss: 0.6937 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 49/50\n",
      "1649/1649 [==============================] - 0s 35us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5016 - recall_m: 0.5016 - val_loss: 0.6937 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "Epoch 50/50\n",
      "1649/1649 [==============================] - 0s 36us/step - loss: 0.6931 - accuracy: 0.5064 - f1_m: 0.5101 - recall_m: 0.5101 - val_loss: 0.6937 - val_accuracy: 0.4746 - val_f1_m: 0.4945 - val_recall_m: 0.4945\n",
      "CNN Error: 52.56%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200,verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[3]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6937344788639078, 0.47457626461982727, 0.4743865728378296, 0.47438663244247437]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
