{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>BRANCHCOUNT</th>\n",
       "      <th>CALLPAIRS</th>\n",
       "      <th>LOCCODEANDCOMMENT</th>\n",
       "      <th>LOCCOMMENTS</th>\n",
       "      <th>CONDITIONCOUNT</th>\n",
       "      <th>CYCLOMATICCOMPLEXITY</th>\n",
       "      <th>CYCLOMATICDENSITY</th>\n",
       "      <th>DECISIONCOUNT</th>\n",
       "      <th>DECISIONDENSITY</th>\n",
       "      <th>...</th>\n",
       "      <th>NODECOUNT</th>\n",
       "      <th>NORMALIZEDCYLOMATICCOMPLEXITY</th>\n",
       "      <th>NUMOPERANDS</th>\n",
       "      <th>NUMOPERATORS</th>\n",
       "      <th>NUMUNIQUEOPERANDS</th>\n",
       "      <th>NUMUNIQUEOPERATORS</th>\n",
       "      <th>NUMBEROFLINES</th>\n",
       "      <th>PERCENTCOMMENTS</th>\n",
       "      <th>LOCTOTAL</th>\n",
       "      <th>Defective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>102</td>\n",
       "      <td>185</td>\n",
       "      <td>54</td>\n",
       "      <td>19</td>\n",
       "      <td>73</td>\n",
       "      <td>13.33</td>\n",
       "      <td>53</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.22</td>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.27</td>\n",
       "      <td>2</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.19</td>\n",
       "      <td>34</td>\n",
       "      <td>51</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>8.33</td>\n",
       "      <td>11</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>43</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>22</td>\n",
       "      <td>0.21</td>\n",
       "      <td>34</td>\n",
       "      <td>2.24</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>0.18</td>\n",
       "      <td>208</td>\n",
       "      <td>349</td>\n",
       "      <td>51</td>\n",
       "      <td>24</td>\n",
       "      <td>119</td>\n",
       "      <td>3.74</td>\n",
       "      <td>103</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.10</td>\n",
       "      <td>4</td>\n",
       "      <td>2.00</td>\n",
       "      <td>...</td>\n",
       "      <td>37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>152</td>\n",
       "      <td>215</td>\n",
       "      <td>71</td>\n",
       "      <td>18</td>\n",
       "      <td>102</td>\n",
       "      <td>10.23</td>\n",
       "      <td>79</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LOC   BRANCHCOUNT   CALLPAIRS   LOCCODEANDCOMMENT   LOCCOMMENTS  \\\n",
       "0   12            15          20                   1             7   \n",
       "1    0             3           4                   0             0   \n",
       "2    3             5           3                   0             1   \n",
       "3   11            43          16                   0             4   \n",
       "4    9            11          13                   0             9   \n",
       "\n",
       "    CONDITIONCOUNT   CYCLOMATICCOMPLEXITY   CYCLOMATICDENSITY   DECISIONCOUNT  \\\n",
       "0               16                      9                0.70               8   \n",
       "1                4                      2                0.25               2   \n",
       "2                6                      3                0.27               2   \n",
       "3               76                     22                0.21              34   \n",
       "4                8                      8                0.10               4   \n",
       "\n",
       "    DECISIONDENSITY  ...   NODECOUNT   NORMALIZEDCYLOMATICCOMPLEXITY  \\\n",
       "0              2.00  ...          49                            0.12   \n",
       "1              2.00  ...           9                            0.22   \n",
       "2              3.00  ...          12                            0.19   \n",
       "3              2.24  ...          99                            0.18   \n",
       "4              2.00  ...          37                            0.08   \n",
       "\n",
       "    NUMOPERANDS   NUMOPERATORS   NUMUNIQUEOPERANDS   NUMUNIQUEOPERATORS  \\\n",
       "0           102            185                  54                   19   \n",
       "1            15             27                  10                   12   \n",
       "2            34             51                  15                   12   \n",
       "3           208            349                  51                   24   \n",
       "4           152            215                  71                   18   \n",
       "\n",
       "    NUMBEROFLINES   PERCENTCOMMENTS   LOCTOTAL   Defective  \n",
       "0              73             13.33         53           Y  \n",
       "1               9              0.00          8           N  \n",
       "2              16              8.33         11           N  \n",
       "3             119              3.74        103           N  \n",
       "4             102             10.23         79           Y  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"dataset/KC3.csv\")\n",
    "data1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LOC</th>\n",
       "      <th>BRANCHCOUNT</th>\n",
       "      <th>CALLPAIRS</th>\n",
       "      <th>LOCCODEANDCOMMENT</th>\n",
       "      <th>LOCCOMMENTS</th>\n",
       "      <th>CONDITIONCOUNT</th>\n",
       "      <th>CYCLOMATICCOMPLEXITY</th>\n",
       "      <th>CYCLOMATICDENSITY</th>\n",
       "      <th>DECISIONCOUNT</th>\n",
       "      <th>DECISIONDENSITY</th>\n",
       "      <th>...</th>\n",
       "      <th>MULTIPLECONDITIONCOUNT</th>\n",
       "      <th>NODECOUNT</th>\n",
       "      <th>NORMALIZEDCYLOMATICCOMPLEXITY</th>\n",
       "      <th>NUMOPERANDS</th>\n",
       "      <th>NUMOPERATORS</th>\n",
       "      <th>NUMUNIQUEOPERANDS</th>\n",
       "      <th>NUMUNIQUEOPERATORS</th>\n",
       "      <th>NUMBEROFLINES</th>\n",
       "      <th>PERCENTCOMMENTS</th>\n",
       "      <th>LOCTOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.809278</td>\n",
       "      <td>10.835052</td>\n",
       "      <td>9.515464</td>\n",
       "      <td>0.231959</td>\n",
       "      <td>2.463918</td>\n",
       "      <td>14.113402</td>\n",
       "      <td>6.350515</td>\n",
       "      <td>0.233351</td>\n",
       "      <td>6.628866</td>\n",
       "      <td>2.127010</td>\n",
       "      <td>...</td>\n",
       "      <td>7.061856</td>\n",
       "      <td>33.690722</td>\n",
       "      <td>0.182680</td>\n",
       "      <td>69.005155</td>\n",
       "      <td>117.809278</td>\n",
       "      <td>29.314433</td>\n",
       "      <td>16.072165</td>\n",
       "      <td>41.304124</td>\n",
       "      <td>5.660619</td>\n",
       "      <td>32.597938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.785431</td>\n",
       "      <td>10.075035</td>\n",
       "      <td>7.841187</td>\n",
       "      <td>0.847312</td>\n",
       "      <td>4.788938</td>\n",
       "      <td>14.259168</td>\n",
       "      <td>5.623860</td>\n",
       "      <td>0.092901</td>\n",
       "      <td>6.581210</td>\n",
       "      <td>0.320942</td>\n",
       "      <td>...</td>\n",
       "      <td>7.129904</td>\n",
       "      <td>32.163881</td>\n",
       "      <td>0.070344</td>\n",
       "      <td>78.049639</td>\n",
       "      <td>126.712394</td>\n",
       "      <td>25.492437</td>\n",
       "      <td>4.896329</td>\n",
       "      <td>42.817425</td>\n",
       "      <td>8.538215</td>\n",
       "      <td>34.191372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>41.250000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>42.750000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>88.500000</td>\n",
       "      <td>151.250000</td>\n",
       "      <td>40.500000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>9.535000</td>\n",
       "      <td>43.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>201.000000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>556.000000</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>242.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              LOC   BRANCHCOUNT   CALLPAIRS   LOCCODEANDCOMMENT   LOCCOMMENTS  \\\n",
       "count  194.000000    194.000000  194.000000          194.000000    194.000000   \n",
       "mean     4.809278     10.835052    9.515464            0.231959      2.463918   \n",
       "std      5.785431     10.075035    7.841187            0.847312      4.788938   \n",
       "min      0.000000      3.000000    1.000000            0.000000      0.000000   \n",
       "25%      1.000000      3.000000    4.000000            0.000000      0.000000   \n",
       "50%      3.000000      7.000000    7.000000            0.000000      0.000000   \n",
       "75%      7.000000     13.000000   12.000000            0.000000      3.000000   \n",
       "max     28.000000     59.000000   46.000000            9.000000     38.000000   \n",
       "\n",
       "        CONDITIONCOUNT   CYCLOMATICCOMPLEXITY   CYCLOMATICDENSITY  \\\n",
       "count       194.000000             194.000000          194.000000   \n",
       "mean         14.113402               6.350515            0.233351   \n",
       "std          14.259168               5.623860            0.092901   \n",
       "min           4.000000               2.000000            0.090000   \n",
       "25%           4.000000               2.000000            0.170000   \n",
       "50%           8.000000               4.000000            0.220000   \n",
       "75%          18.000000               7.750000            0.270000   \n",
       "max          76.000000              36.000000            0.700000   \n",
       "\n",
       "        DECISIONCOUNT   DECISIONDENSITY  ...   MULTIPLECONDITIONCOUNT  \\\n",
       "count      194.000000        194.000000  ...               194.000000   \n",
       "mean         6.628866          2.127010  ...                 7.061856   \n",
       "std          6.581210          0.320942  ...                 7.129904   \n",
       "min          2.000000          2.000000  ...                 2.000000   \n",
       "25%          2.000000          2.000000  ...                 2.000000   \n",
       "50%          4.000000          2.000000  ...                 4.000000   \n",
       "75%          8.000000          2.070000  ...                 9.000000   \n",
       "max         34.000000          4.000000  ...                38.000000   \n",
       "\n",
       "        NODECOUNT   NORMALIZEDCYLOMATICCOMPLEXITY   NUMOPERANDS  \\\n",
       "count  194.000000                      194.000000    194.000000   \n",
       "mean    33.690722                        0.182680     69.005155   \n",
       "std     32.163881                        0.070344     78.049639   \n",
       "min      6.000000                        0.060000      5.000000   \n",
       "25%     13.000000                        0.130000     22.000000   \n",
       "50%     22.000000                        0.170000     39.000000   \n",
       "75%     42.750000                        0.210000     88.500000   \n",
       "max    201.000000                        0.430000    556.000000   \n",
       "\n",
       "        NUMOPERATORS   NUMUNIQUEOPERANDS   NUMUNIQUEOPERATORS   NUMBEROFLINES  \\\n",
       "count     194.000000          194.000000           194.000000      194.000000   \n",
       "mean      117.809278           29.314433            16.072165       41.304124   \n",
       "std       126.712394           25.492437             4.896329       42.817425   \n",
       "min        13.000000            4.000000             7.000000        5.000000   \n",
       "25%        41.250000           13.000000            13.000000       14.000000   \n",
       "50%        69.500000           20.000000            16.000000       25.000000   \n",
       "75%       151.250000           40.500000            19.000000       55.500000   \n",
       "max       857.000000          159.000000            31.000000      310.000000   \n",
       "\n",
       "        PERCENTCOMMENTS    LOCTOTAL  \n",
       "count        194.000000  194.000000  \n",
       "mean           5.660619   32.597938  \n",
       "std            8.538215   34.191372  \n",
       "min            0.000000    4.000000  \n",
       "25%            0.000000   11.250000  \n",
       "50%            0.465000   20.000000  \n",
       "75%            9.535000   43.000000  \n",
       "max           43.750000  242.000000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 40)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, 0, 0, 4, 2, 0.25, 2, 2.0, 2, 1.0, 9, 1, 0.0, 8, 2, 2, 1.0,\n",
       "       20.81, 9.0, 1685.67, 0.06, 42, 0.11, 93.65, 187.3, 0.5, 1, 2, 9,\n",
       "       0.22, 15, 27, 10, 12, 9, 0.0, 8, 0], dtype=object)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2=data1.values\n",
    "for i in range(194):\n",
    "    if data2[i][39]=='Y':\n",
    "        data2[i][39]=1\n",
    "    if data2[i][39]=='N':\n",
    "        data2[i][39]=0\n",
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(data2).astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=X[:,39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X[:,0:39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((316, 39), (316,))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler,SMOTE\n",
    "#os =  RandomOverSampler()\n",
    "X_res, y_res = SMOTE().fit_resample(X, y)\n",
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(316, 39, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape\n",
    "X_res=X_res.reshape(316,39,1)\n",
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "def baseline_model():\n",
    "# create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=1, kernel_size=3 , input_shape=(39,1),activation= 'relu' ))\n",
    "    model.add(MaxPooling1D(pool_size=4))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(21, activation= 'relu' ))\n",
    "    model.add(Dense(num_classes, activation= 'sigmoid' ))\n",
    "# Compile model\n",
    "    model.compile(loss= 'binary_crossentropy' , optimizer= 'adam' , metrics=['accuracy' ,f1_m,recall_m])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2)\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 252 samples, validate on 64 samples\n",
      "Epoch 1/50\n",
      "252/252 [==============================] - 1s 6ms/step - loss: 0.6931 - accuracy: 0.5079 - f1_m: 0.2692 - recall_m: 0.2692 - val_loss: 0.6933 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 2/50\n",
      "252/252 [==============================] - 0s 256us/step - loss: 0.6931 - accuracy: 0.5238 - f1_m: 0.5079 - recall_m: 0.5079 - val_loss: 0.6935 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 3/50\n",
      "252/252 [==============================] - 0s 138us/step - loss: 0.6931 - accuracy: 0.5238 - f1_m: 0.5790 - recall_m: 0.5790 - val_loss: 0.6935 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 4/50\n",
      "252/252 [==============================] - 0s 189us/step - loss: 0.6931 - accuracy: 0.5238 - f1_m: 0.5008 - recall_m: 0.5008 - val_loss: 0.6936 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 5/50\n",
      "252/252 [==============================] - 0s 83us/step - loss: 0.6930 - accuracy: 0.5238 - f1_m: 0.5221 - recall_m: 0.5221 - val_loss: 0.6937 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 6/50\n",
      "252/252 [==============================] - 0s 214us/step - loss: 0.6930 - accuracy: 0.5238 - f1_m: 0.5150 - recall_m: 0.5150 - val_loss: 0.6938 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 7/50\n",
      "252/252 [==============================] - 0s 228us/step - loss: 0.6930 - accuracy: 0.5238 - f1_m: 0.5577 - recall_m: 0.5577 - val_loss: 0.6939 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 8/50\n",
      "252/252 [==============================] - 0s 250us/step - loss: 0.6930 - accuracy: 0.5238 - f1_m: 0.4937 - recall_m: 0.4937 - val_loss: 0.6940 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 9/50\n",
      "252/252 [==============================] - 0s 260us/step - loss: 0.6929 - accuracy: 0.5238 - f1_m: 0.5577 - recall_m: 0.5577 - val_loss: 0.6940 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 10/50\n",
      "252/252 [==============================] - 0s 225us/step - loss: 0.6929 - accuracy: 0.5238 - f1_m: 0.5221 - recall_m: 0.5221 - val_loss: 0.6941 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 11/50\n",
      "252/252 [==============================] - 0s 192us/step - loss: 0.6929 - accuracy: 0.5238 - f1_m: 0.5221 - recall_m: 0.5221 - val_loss: 0.6942 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 12/50\n",
      "252/252 [==============================] - 0s 204us/step - loss: 0.6929 - accuracy: 0.5238 - f1_m: 0.5363 - recall_m: 0.5363 - val_loss: 0.6943 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 13/50\n",
      "252/252 [==============================] - 0s 323us/step - loss: 0.6929 - accuracy: 0.5238 - f1_m: 0.4723 - recall_m: 0.4723 - val_loss: 0.6944 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 14/50\n",
      "252/252 [==============================] - 0s 374us/step - loss: 0.6929 - accuracy: 0.5238 - f1_m: 0.5648 - recall_m: 0.5648 - val_loss: 0.6945 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 15/50\n",
      "252/252 [==============================] - 0s 272us/step - loss: 0.6928 - accuracy: 0.5238 - f1_m: 0.5363 - recall_m: 0.5363 - val_loss: 0.6945 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 16/50\n",
      "252/252 [==============================] - 0s 152us/step - loss: 0.6928 - accuracy: 0.5238 - f1_m: 0.5079 - recall_m: 0.5079 - val_loss: 0.6946 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 17/50\n",
      "252/252 [==============================] - 0s 268us/step - loss: 0.6928 - accuracy: 0.5238 - f1_m: 0.5079 - recall_m: 0.5079 - val_loss: 0.6947 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 18/50\n",
      "252/252 [==============================] - 0s 439us/step - loss: 0.6928 - accuracy: 0.5238 - f1_m: 0.5079 - recall_m: 0.5079 - val_loss: 0.6947 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 19/50\n",
      "252/252 [==============================] - 0s 229us/step - loss: 0.6928 - accuracy: 0.5238 - f1_m: 0.5292 - recall_m: 0.5292 - val_loss: 0.6948 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 20/50\n",
      "252/252 [==============================] - 0s 211us/step - loss: 0.6928 - accuracy: 0.5238 - f1_m: 0.4865 - recall_m: 0.4865 - val_loss: 0.6949 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 21/50\n",
      "252/252 [==============================] - 0s 243us/step - loss: 0.6928 - accuracy: 0.5238 - f1_m: 0.5292 - recall_m: 0.5292 - val_loss: 0.6949 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 22/50\n",
      "252/252 [==============================] - 0s 134us/step - loss: 0.6928 - accuracy: 0.5238 - f1_m: 0.5292 - recall_m: 0.5292 - val_loss: 0.6950 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 23/50\n",
      "252/252 [==============================] - 0s 238us/step - loss: 0.6927 - accuracy: 0.5238 - f1_m: 0.5435 - recall_m: 0.5435 - val_loss: 0.6950 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 24/50\n",
      "252/252 [==============================] - 0s 169us/step - loss: 0.6927 - accuracy: 0.5238 - f1_m: 0.5292 - recall_m: 0.5292 - val_loss: 0.6951 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 25/50\n",
      "252/252 [==============================] - 0s 252us/step - loss: 0.6927 - accuracy: 0.5238 - f1_m: 0.4865 - recall_m: 0.4865 - val_loss: 0.6952 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 26/50\n",
      "252/252 [==============================] - 0s 203us/step - loss: 0.6927 - accuracy: 0.5238 - f1_m: 0.5150 - recall_m: 0.5150 - val_loss: 0.6952 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 27/50\n",
      "252/252 [==============================] - 0s 264us/step - loss: 0.6927 - accuracy: 0.5238 - f1_m: 0.5221 - recall_m: 0.5221 - val_loss: 0.6953 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 28/50\n",
      "252/252 [==============================] - 0s 261us/step - loss: 0.6927 - accuracy: 0.5238 - f1_m: 0.5363 - recall_m: 0.5363 - val_loss: 0.6953 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 29/50\n",
      "252/252 [==============================] - 0s 235us/step - loss: 0.6927 - accuracy: 0.5238 - f1_m: 0.5363 - recall_m: 0.5363 - val_loss: 0.6954 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 30/50\n",
      "252/252 [==============================] - 0s 278us/step - loss: 0.6927 - accuracy: 0.5238 - f1_m: 0.5506 - recall_m: 0.5506 - val_loss: 0.6955 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 31/50\n",
      "252/252 [==============================] - 0s 277us/step - loss: 0.6926 - accuracy: 0.5238 - f1_m: 0.5435 - recall_m: 0.5435 - val_loss: 0.6956 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 32/50\n",
      "252/252 [==============================] - 0s 220us/step - loss: 0.6926 - accuracy: 0.5238 - f1_m: 0.5363 - recall_m: 0.5363 - val_loss: 0.6957 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 33/50\n",
      "252/252 [==============================] - 0s 71us/step - loss: 0.6926 - accuracy: 0.5238 - f1_m: 0.5292 - recall_m: 0.5292 - val_loss: 0.6958 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 34/50\n",
      "252/252 [==============================] - 0s 362us/step - loss: 0.6926 - accuracy: 0.5238 - f1_m: 0.5150 - recall_m: 0.5150 - val_loss: 0.6959 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 35/50\n",
      "252/252 [==============================] - 0s 248us/step - loss: 0.6926 - accuracy: 0.5238 - f1_m: 0.5435 - recall_m: 0.5435 - val_loss: 0.6960 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 36/50\n",
      "252/252 [==============================] - 0s 189us/step - loss: 0.6926 - accuracy: 0.5238 - f1_m: 0.4865 - recall_m: 0.4865 - val_loss: 0.6961 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 37/50\n",
      "252/252 [==============================] - 0s 167us/step - loss: 0.6925 - accuracy: 0.5238 - f1_m: 0.5008 - recall_m: 0.5008 - val_loss: 0.6961 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50\n",
      "252/252 [==============================] - 0s 135us/step - loss: 0.6925 - accuracy: 0.5238 - f1_m: 0.5363 - recall_m: 0.5363 - val_loss: 0.6962 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 39/50\n",
      "252/252 [==============================] - 0s 209us/step - loss: 0.6925 - accuracy: 0.5238 - f1_m: 0.5079 - recall_m: 0.5079 - val_loss: 0.6962 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 40/50\n",
      "252/252 [==============================] - 0s 242us/step - loss: 0.6925 - accuracy: 0.5238 - f1_m: 0.5221 - recall_m: 0.5221 - val_loss: 0.6963 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 41/50\n",
      "252/252 [==============================] - 0s 198us/step - loss: 0.6925 - accuracy: 0.5238 - f1_m: 0.5150 - recall_m: 0.5150 - val_loss: 0.6963 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 42/50\n",
      "252/252 [==============================] - 0s 222us/step - loss: 0.6925 - accuracy: 0.5238 - f1_m: 0.5221 - recall_m: 0.5221 - val_loss: 0.6964 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 43/50\n",
      "252/252 [==============================] - 0s 272us/step - loss: 0.6925 - accuracy: 0.5238 - f1_m: 0.5221 - recall_m: 0.5221 - val_loss: 0.6965 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 44/50\n",
      "252/252 [==============================] - 0s 136us/step - loss: 0.6925 - accuracy: 0.5238 - f1_m: 0.5506 - recall_m: 0.5506 - val_loss: 0.6965 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 45/50\n",
      "252/252 [==============================] - 0s 125us/step - loss: 0.6925 - accuracy: 0.5238 - f1_m: 0.5221 - recall_m: 0.5221 - val_loss: 0.6966 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 46/50\n",
      "252/252 [==============================] - 0s 123us/step - loss: 0.6925 - accuracy: 0.5238 - f1_m: 0.5150 - recall_m: 0.5150 - val_loss: 0.6967 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 47/50\n",
      "252/252 [==============================] - 0s 117us/step - loss: 0.6924 - accuracy: 0.5238 - f1_m: 0.5506 - recall_m: 0.5506 - val_loss: 0.6967 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 48/50\n",
      "252/252 [==============================] - 0s 153us/step - loss: 0.6924 - accuracy: 0.5238 - f1_m: 0.5292 - recall_m: 0.5292 - val_loss: 0.6968 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 49/50\n",
      "252/252 [==============================] - 0s 119us/step - loss: 0.6924 - accuracy: 0.5238 - f1_m: 0.5079 - recall_m: 0.5079 - val_loss: 0.6969 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "Epoch 50/50\n",
      "252/252 [==============================] - 0s 159us/step - loss: 0.6924 - accuracy: 0.5238 - f1_m: 0.5079 - recall_m: 0.5079 - val_loss: 0.6970 - val_accuracy: 0.4062 - val_f1_m: 0.4062 - val_recall_m: 0.4062\n",
      "CNN Error: 59.38%\n"
     ]
    }
   ],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=200,verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"CNN Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6969784498214722, 0.40625, 0.4062499403953552, 0.40625]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
